<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coding Automaton</title>
    <link>http://jessezhuang.github.io/</link>
    <description>Recent content on Coding Automaton</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Aug 2016 17:12:46 -0700</lastBuildDate>
    <atom:link href="http://jessezhuang.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Algorithm Question Substring Search KMP</title>
      <link>http://jessezhuang.github.io/article/algorithm-string-KMP/</link>
      <pubDate>Fri, 05 Aug 2016 17:12:46 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/algorithm-string-KMP/</guid>
      <description>

&lt;h1 id=&#34;question&#34;&gt;Question&lt;/h1&gt;

&lt;p&gt;LeetCode has this question Implement strStr().&lt;/p&gt;

&lt;p&gt;Returns the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack.&lt;/p&gt;

&lt;p&gt;Tags: Two Pointers, String.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s denote haystack length &lt;code&gt;N&lt;/code&gt;, needle length &lt;code&gt;M&lt;/code&gt;, character table size &lt;code&gt;R&lt;/code&gt; (256 for extended ASCII).&lt;/p&gt;

&lt;p&gt;Java&amp;rsquo;s &lt;code&gt;String&lt;/code&gt; class method &lt;code&gt;indexOf()&lt;/code&gt; uses brute force algorithm O(MN).&lt;/p&gt;

&lt;p&gt;Examples:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;haystacsflksdjflkshhaystackneeneeneedle
         needle
naslkfjskjlhhhh
needle
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;method-1-2d-dfa&#34;&gt;Method 1 2D DFA&lt;/h2&gt;

&lt;p&gt;KMP Knuth Morris Pratt O(N) time complexity.&lt;/p&gt;

&lt;p&gt;2D array DFA[256][M] gives the next character index to match against i.&lt;/p&gt;

&lt;p&gt;Example: needle &amp;ldquo;ABABAC&amp;rdquo;. DFA[r][j] where r &amp;lt; R, j &amp;lt; M.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;j    :  0 1 2 3 4 5 6
state:  0 0 1 2 3 0
r       A B A B A C
A       1 1 3 1 5 1 
B       0 2 0 4 0 4
C       0 0 0 0 0 6
D       0 0 0 0 0 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Steps to build DFA:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;copy mismatched cases (first column all 0).&lt;/li&gt;
&lt;li&gt;set matched character to go to next state (first column DFA[needle.charAt(0)][0] = 1).&lt;/li&gt;
&lt;li&gt;start state 0, update state for j in [1, M-1].&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;DFA[needle.charAt(0)][0] = 1;
int state = 0;
for (int j = 1; j &amp;lt; M; j++) {
  for (int r = 0; r &amp;lt; 256; r++) DFA[r][j] = DFA[r][state];
  DFA[needle.charAt(j)][j] = j + 1;    
  state = DFA[needle.charAt(j)][state];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note DFA[&amp;rsquo;D&amp;rsquo;][5] = 0 but DFA[&amp;lsquo;B&amp;rsquo;][5] = 4.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (int i = 0, j = 0; i &amp;lt; N &amp;amp;&amp;amp; j &amp;lt; M; i++) {
  //no backup, so can increment i
  j = DFA[haystack.charAt(i)][j];
}
if (j == M) return i - M;
else return -1;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;method-2-1d-restart-table-array&#34;&gt;Method 2: 1D Restart Table Array&lt;/h2&gt;

&lt;p&gt;restart[M]
restart[j - 1] gives which character in needle to match against index i in haystack when a mismatch happens at index j of needle.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;          A B A B A C
restart:  0 0 1 2 3 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compare suffix needle[j, M-1] with needle, longest common prefix&amp;rsquo;s length.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;int state = 0;
for (int j = 1; j &amp;lt; M;) {
  if (needle.charAt(j) == needle.charAt(state)) {
    restart[j++] = ++state;
  } else if (state == 0) j++;
  else state = restart[state - 1];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To compare, now has to back up, cannot operate on stream like standard input without buffering.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for (int i = 0, j = 0; i &amp;lt; N - M &amp;amp;&amp;amp; j &amp;lt; M;) {
  if (needle.charAt(j) == haystack.charAt(i)) {
    j++;
    i++;
  }
  else if (j == 0) i++;
  else j = restart[j - 1]; 
}
if (j == M) return i - j;
else return -1;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Question: worst case operations 2N, practical 1.1 N. Why 2N?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sorting Algorithm Summary</title>
      <link>http://jessezhuang.github.io/article/algorithm-sorting-summary/</link>
      <pubDate>Mon, 18 Jul 2016 00:52:13 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/algorithm-sorting-summary/</guid>
      <description>&lt;p&gt;The following table summarizes common characteristics of popular sorting algorithms, not including string sort algorithms (I may add those later here or write another separate post).&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;algorithm&lt;/th&gt;
&lt;th&gt;In Place?&lt;/th&gt;
&lt;th&gt;Stable?&lt;/th&gt;
&lt;th&gt;parallel?&lt;/th&gt;
&lt;th&gt;worst&lt;/th&gt;
&lt;th&gt;average&lt;/th&gt;
&lt;th&gt;best&lt;/th&gt;
&lt;th&gt;remarks&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;selection&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/2&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/2&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/2&lt;/td&gt;
&lt;td&gt;N exchanges&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;insertion&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/2&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/4&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;use for small N or partially ordered&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;shell&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;tight code, sub quadratic&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;merge&lt;/td&gt;
&lt;td&gt;n&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;NlgN&lt;/td&gt;
&lt;td&gt;NlgN&lt;/td&gt;
&lt;td&gt;NlgN&lt;/td&gt;
&lt;td&gt;NlgN guarantee, stable&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;quick&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/2&lt;/td&gt;
&lt;td&gt;2NlnN&lt;/td&gt;
&lt;td&gt;NlgN&lt;/td&gt;
&lt;td&gt;probabilistic guarantee, fastest in practice&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;heap&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;2NlgN&lt;/td&gt;
&lt;td&gt;2NlgN&lt;/td&gt;
&lt;td&gt;NlgN&lt;/td&gt;
&lt;td&gt;NlgN guarantee, in place&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;counting&lt;/td&gt;
&lt;td&gt;n&lt;sup&gt;*&lt;/sup&gt;&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;N+R&lt;/td&gt;
&lt;td&gt;N+R&lt;/td&gt;
&lt;td&gt;N+R&lt;/td&gt;
&lt;td&gt;integer keys, suitable where max-min (R) not &amp;gt;&amp;gt; N, often used as subroutine of radix sort. If sparse, can use hashmap to save space.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;bucket&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;N&lt;sup&gt;2&lt;/sup&gt;/2&lt;/td&gt;
&lt;td&gt;N+k&lt;/td&gt;
&lt;td&gt;N+k&lt;/td&gt;
&lt;td&gt;k denotes number of buckets, needs linked lists, dynamic arrays to hold items in buckets&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Cartesian&lt;/td&gt;
&lt;td&gt;y&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;n&lt;/td&gt;
&lt;td&gt;Nlogk&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;k denotes average of number of consecutive pairs, can be viewed as a version of selection and heap sort maintaining a priority queue&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are in place merge sort algorithms which are a little nontrivial to implement, one way is to do in place merge with bottom up approach. Merge sort on linked lists uses O(1) extra space.&lt;/li&gt;
&lt;li&gt;3-way quick sort can improve best case running time to O(N) in presence of duplicate keys.&lt;/li&gt;
&lt;li&gt;Counting sort with key indexed counting is stable, uses extra O(N) space for output array. If disregarding the count array, the input array can be used for returning although it is no longer stable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Implementations in Core Java as of JDK 1.8, &lt;code&gt;DualPivotQuickSort&lt;/code&gt; (cut off threshhold of 47 to insertion sort) is used for primitives and a variant of &lt;code&gt;TimSort&lt;/code&gt; (a stable, adaptive, iterative merge sort adapted from Tim Peter&amp;rsquo;s list sort for Python, uses binary insertion sort) is used for objects.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Git Cheatsheet</title>
      <link>http://jessezhuang.github.io/article/git-cheatsheet/</link>
      <pubDate>Wed, 06 Jul 2016 16:39:13 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/git-cheatsheet/</guid>
      <description>

&lt;h1 id=&#34;basic-snapshotting&#34;&gt;Basic Snapshotting&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git-mv&lt;/code&gt; - Move or rename a file, a directory, or a symlink&lt;/p&gt;

&lt;p&gt;&lt;code&gt;git mv [-v] [-f] [-n] [-k] &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;&lt;/code&gt; rename&lt;br /&gt;
&lt;code&gt;git mv [-v] [-f] [-n] [-k] &amp;lt;source&amp;gt; ... &amp;lt;destination directory&amp;gt;&lt;/code&gt; move into existing directory&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git mv &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt; # rename a directory
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;branch-related&#34;&gt;Branch Related&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git branch [options] &amp;lt;branchname&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git branch # show all branches with current marked with *
git branch -vv # show all local and tracked remote branches
git checkout dev
git branch jesse
# creates branch named &amp;quot;jesse&amp;quot; off from &amp;quot;dev&amp;quot; branch
git checkout -b jesse
# creates and switch to branch &amp;quot;jesse&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;merge&#34;&gt;Merge&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git merge [options] [&amp;lt;commit&amp;gt;...]&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;git merge --abort&lt;/code&gt; may not be able to fully recover&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git merge --no-ff
# no fast forwarding creates merge commit for FF
git merge jesse
# merge commits on jesse into current branch
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git merge --no-ff 
# no fast forwarding creates merge commit for FF
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;working-with-remotes&#34;&gt;Working with Remotes&lt;/h1&gt;

&lt;p&gt;&lt;code&gt;git fetch [&amp;lt;options&amp;gt;] [&amp;lt;repository&amp;gt; [&amp;lt;refspec&amp;gt;]]&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch origin # fetch branches and/or tags from &amp;quot;origin&amp;quot; remote
git fetch -a # fetches from all remotes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;git remote [-v | --verbose]&lt;/code&gt;&lt;br /&gt;
&lt;code&gt;git remote add [-f] [--[no-]tags] &amp;lt;name&amp;gt; &amp;lt;url&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git remote # show all remote repositories
git remote -v # show all remote repositories with urls

# add remote repo and name it origin
git remote add origin https://github.com/user/repo.git
# runs git fetch origin immediately after
git remote add -f origin https://github.com/user/repo.git
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;merge-a-pull-request-on-github&#34;&gt;Merge a Pull Request on Github&lt;/h3&gt;

&lt;p&gt;Step 1: From your project repository, bring in the changes and test.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git fetch origin
# not necessary if you just pushed local 
git checkout -b lname origin/rname 
git merge dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Step 2: Merge the changes and update on GitHub.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout dev
git merge --no-ff jesse # no fast fowarding, create a merge commit
git push origin dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;pull-all-remote-branches&#34;&gt;Pull All Remote Branches&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# the first line creates local branch with same name tracking remote branch
git branch -r | grep -v &#39;\-&amp;gt;&#39; | while read remote; do git branch --track &amp;quot;${remote#origin/}&amp;quot; &amp;quot;$remote&amp;quot;; done
git fetch --all
git pull --all
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;delete-a-remote-branch&#34;&gt;Delete a Remote Branch&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git push origin --delete &amp;lt;branchName&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Virtualbox Tips for Ubuntu Guest in Windows Host</title>
      <link>http://jessezhuang.github.io/article/virtualbox-tips/</link>
      <pubDate>Sat, 02 Jul 2016 18:17:10 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/virtualbox-tips/</guid>
      <description>

&lt;p&gt;For Ubuntu tips, see &lt;a href=&#34;http://jessezhuang.github.io/
article/ubuntu/&#34;&gt;http://jessezhuang.github.io/
article/ubuntu/&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;how-to-get-shared-folder-write-access&#34;&gt;How to Get Shared Folder Write Access&lt;/h1&gt;

&lt;p&gt;When used as a virtual machine guest (Ubuntu 14.04LTS in Windows 10 host with Oracle VirtualBox), to get access to shared folder, run the following command in shell, replace &lt;code&gt;username&lt;/code&gt; with your ubuntu username.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# replace username with your actual ubuntu username
$ sudo usermod -a -G vboxsf username
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After that, reboot the VM and you should have write access to the shared folder.&lt;/p&gt;

&lt;h1 id=&#34;how-to-create-virtualenv-in-shared-folder&#34;&gt;How to Create Virtualenv in Shared Folder&lt;/h1&gt;

&lt;p&gt;Creating symbolic links in a VirtualBox shared folder is disabled, which will forbid you to create a virtualenv in a shared folder from the host machine. Simple test in terminal: &lt;code&gt;$ ln -s test&lt;/code&gt;, Either you&amp;rsquo;ll get a &lt;code&gt;failed to create symbolic link &#39;./testfile&#39;: Read-only file system&lt;/code&gt; or &lt;code&gt;Protocol error&lt;/code&gt;. Shutdown VM and close Virtualbox Manager in Windows host. Open an admin command prompt,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;C:\WINDOWS\system32&amp;gt;VBoxManage setextradata VM_name 
  VBoxInternal2/SharedFoldersEnableSymlinksCreate/shared_folder 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have not added virtualbox commands to your path, either do so or run &lt;code&gt;VBoxManage&lt;/code&gt; from the folder where it is located. Replace &lt;code&gt;VM_name&lt;/code&gt; with the name of the virtual machine,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.stack.imgur.com/NrMzq.jpg&#34; alt=&#34;vmname in virtualbox manager&#34; /&gt;&lt;/p&gt;

&lt;p&gt;and the name of &lt;code&gt;shared_folder&lt;/code&gt; with the name of the shared folder in the settings of your virtual machine,&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://i.stack.imgur.com/yboaG.jpg&#34; alt=&#34;shared folder name screenshot&#34; /&gt;.&lt;/p&gt;

&lt;p&gt;You can check the settings with the command below and should find one key about your shared folder indicating that it was enabled as in the second line below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-console&#34;&gt;C:\WINDOWS\system32&amp;gt;vboxmanage getextradata ubuntu14-ppbdmmdd enumerate
Key: VBoxInternal2/SharedFoldersEnableSymlinksCreate/shared_folder, Value: 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that you still need to run the VirtualBox Manager as an administrator from Windows in order for the creation of virtualenv (symlinks) to work properly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Vim Cheatsheet</title>
      <link>http://jessezhuang.github.io/article/vim-cheatsheet/</link>
      <pubDate>Thu, 30 Jun 2016 00:37:56 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/vim-cheatsheet/</guid>
      <description>

&lt;p&gt;For Ubuntu Linux,&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Terms:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;C-x&lt;/code&gt; stands for &lt;code&gt;ctrl-x&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&#34;copy-pasting&#34;&gt;Copy/Pasting&lt;/h1&gt;

&lt;p&gt;In normal mode:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;command&lt;/th&gt;
&lt;th&gt;effect&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;3y, p&lt;/td&gt;
&lt;td&gt;copy 3 lines, paste after cursor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&amp;ldquo;ayy, &amp;ldquo;ap&lt;/td&gt;
&lt;td&gt;copy current line to buffer a, paste from buffer a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;v/V&lt;/td&gt;
&lt;td&gt;start selecting character, whole line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;5ly&lt;/td&gt;
&lt;td&gt;yanks into default buffer 5 characters from cursor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&amp;ldquo;hy&lt;/td&gt;
&lt;td&gt;yanks into register h, use + register for system clipboard&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In insert mode:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;command&lt;/th&gt;
&lt;th&gt;effect&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;`C-r{register}&lt;/td&gt;
&lt;td&gt;paste contents of the register&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C-r&amp;rdquo;&lt;/td&gt;
&lt;td&gt;to paste from default register&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C-u&lt;/td&gt;
&lt;td&gt;to delete everything before the cursor on this line&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C-w&lt;/td&gt;
&lt;td&gt;to delete from cursor to the beginning of previous word&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;move-around&#34;&gt;Move Around&lt;/h1&gt;

&lt;p&gt;In normal mode:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;command&lt;/th&gt;
&lt;th&gt;effect&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;100l&lt;/td&gt;
&lt;td&gt;go right 100 positions, useful to navigate a long line.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;10w/10b/10e&lt;/td&gt;
&lt;td&gt;go forward/backward 10 words, e end of word&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;fa, ta&lt;/td&gt;
&lt;td&gt;move to or just before the next letter a&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;/pattern&lt;/td&gt;
&lt;td&gt;move to the next word matches, n/N to repeat search&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;H,M,L # to go to top/mid/bottom of screen&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1G(1gg), G&lt;/td&gt;
&lt;td&gt;go to beginning/end of file&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;),}&lt;/td&gt;
&lt;td&gt;jump forward one sentence/paragraph&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;editing&#34;&gt;Editing&lt;/h1&gt;

&lt;p&gt;In normal mode:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;command&lt;/th&gt;
&lt;th&gt;effect&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;dw/W&lt;/td&gt;
&lt;td&gt;delete word before/after cursor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;x,r&lt;/td&gt;
&lt;td&gt;delete,replace character at cursor&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;.,u,ctrl-r&lt;/td&gt;
&lt;td&gt;repeat, undo, redo&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;q&lt;letter&gt;, @&lt;letter&gt;&lt;/td&gt;
&lt;td&gt;record operations and reapply, type q again to quit&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>How to Install Latest Version Vim in Ubuntu 14.04 LTS</title>
      <link>http://jessezhuang.github.io/article/vim-ubuntu-install/</link>
      <pubDate>Thu, 30 Jun 2016 00:36:25 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/vim-ubuntu-install/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://vim.sexy/img/Vimlogo.svg&#34; alt=&#34;Vim Icon svg&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;ubuntu-comes-with-vim-tiny&#34;&gt;Ubuntu comes with Vim-Tiny&lt;/h1&gt;

&lt;p&gt;First of all, Ubuntu 14.04 LTS comes with Vim.Tiny with the version &lt;code&gt;2:7.4.052-1ubuntu3&lt;/code&gt; which is Vim 7.4.052, already fairly new. Unfortunately I was looking specifically for markdown editing and syntax highlighting and I found that &lt;a href=&#34;http://stackoverflow.com/questions/10964681/enabling-markdown-highlighting-in-vim&#34;&gt;starting from 7.4.480&lt;/a&gt; vim can pick up *.md files as markdown files by default. So I wanted to find a newer version of Vim to install.&lt;/p&gt;

&lt;h1 id=&#34;install-vim-with-ppa&#34;&gt;Install Vim with PPA&lt;/h1&gt;

&lt;p&gt;I have tried to install Vim with debian packages listed on &lt;a href=&#34;http://www.vim.org&#34;&gt;Vim.org&lt;/a&gt; but they did not come with the dependencies. So PPA was an easier way to go. &lt;a href=&#34;https://launchpad.net/~pkg-vim/+archive/ubuntu/vim-daily&#34;&gt;ppa:pkg-vim/vim-daily&lt;/a&gt; has version 7.4.826 which is good enough.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;sudo add-apt-repository ppa:pkg-vim/vim-daily
sudo apt-get update
sudo apt-get install vim
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can use &lt;code&gt;apt-cache policy vim&lt;/code&gt; to check the version of the vim in your repositories.&lt;/p&gt;

&lt;h1 id=&#34;install-from-source&#34;&gt;Install From Source&lt;/h1&gt;

&lt;p&gt;Vim.org has detailed instructions on how to &lt;code&gt;git clone&lt;/code&gt; and install from source for the latest version of Vim and you can custom configure. One suggestion would be to use &lt;a href=&#34;http://asic-linux.com.mx/~izto/checkinstall/index.php&#34;&gt;&lt;code&gt;checkinstall&lt;/code&gt;&lt;/a&gt; just in case you ever want to cleanly remove the installation.&lt;/p&gt;

&lt;p&gt;The Vim 7.4.826 version from the PPA does not have system clipboard support by default. Use &lt;code&gt;vim --version | grep &#39;clipboard&#39;&lt;/code&gt; at shell to check. If you have &lt;code&gt;+clipboard&lt;/code&gt; and/or &lt;code&gt;+xterm_clipboard&lt;/code&gt; then you are good to go. Otherwise you can either install from source or &lt;code&gt;sudo apt-get install vim-gnome&lt;/code&gt; which already has the clipboard support.&lt;/p&gt;

&lt;h1 id=&#34;basic-configuration-to-enable-markdown-highlighting&#34;&gt;Basic Configuration to Enable Markdown Highlighting&lt;/h1&gt;

&lt;p&gt;This ppa version of Vim does not automatically generate ~/.vimrc file but you can create the file yourself and put the following content in the file:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;syntax on
colorscheme industry
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then you are good to go. I am happy to find that mouse/touchpad scrolling also works to go up and down the lines instead of using j and k commands.&lt;/p&gt;

&lt;h1 id=&#34;why-vim&#34;&gt;Why Vim?&lt;/h1&gt;

&lt;p&gt;A lot of people like Vim/Emacs. For me, Vim seems to be a very lightweight text editor which is very similar to Vi that comes with most server command line interfaces. It&amp;rsquo;s good to get familiar with at least the basic usage of Vim. I have been using atom in my Ubuntu but atom has a &lt;a href=&#34;https://github.com/atom/atom/issues/7883&#34;&gt;memory leak issue&lt;/a&gt; which sometimes causes Ubuntu to hang or even restart as an guest OS with Oracle VirtualBox in Windows 10 host. Going to light weight and more basic is also a good way to practice your programming language knowledges when you lose all the autocompletion, not that Vim cannot do autocompletion but you can pretend as if.&lt;/p&gt;

&lt;p&gt;Example memory usage: Vim with a few buffers open switching between editing those files uses &amp;lt; 5 Mb and atom typically uses over 200 Mb memory with similar number of files open.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mongodb Tutorial 6 - Application Engineering</title>
      <link>http://jessezhuang.github.io/article/mongodb-app-engineer/</link>
      <pubDate>Wed, 29 Jun 2016 00:00:00 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/mongodb-app-engineer/</guid>
      <description>

&lt;h1 id=&#34;durability-of-writes&#34;&gt;Durability of Writes&lt;/h1&gt;

&lt;h2 id=&#34;write-concern&#34;&gt;Write Concern&lt;/h2&gt;

&lt;p&gt;How to make sure the writes persistent? Assume application talking to a database server in the scheme below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/mongodb-write.png&#34; alt=&#34;mongodb write concern&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The settings of two parameters affect the write concern:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;w(wait for acknowledgement)&lt;/th&gt;
&lt;th&gt;j(journal)&lt;/th&gt;
&lt;th&gt;effect&lt;/th&gt;
&lt;th&gt;comment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;false&lt;/td&gt;
&lt;td&gt;fast, small window of vulnerability&lt;/td&gt;
&lt;td&gt;default setting&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;true&lt;/td&gt;
&lt;td&gt;slow, no vulnerability&lt;/td&gt;
&lt;td&gt;can be done inside driver at collection, database, or client level&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;unacknowledged write&lt;/td&gt;
&lt;td&gt;do not recommend&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;wait for 2 nodes in replica set to acknowledge write&lt;/td&gt;
&lt;td&gt;w can be 0-3 for a set with 3 nodes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;majority&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;wait for majority to acknowledge, avoid rollback on failover&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;tag values&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;set tags on nodes&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;If the journal has been written to disk and the server crashes, on recovery the server can look in the journal and recreate all the writes that were not yet persisted to the pages.&lt;/p&gt;

&lt;p&gt;Write concern revisited video notes: Write concern (w) value can be set at client, database or collection level within PyMongo. When you call MongoClient, you get a connection to the driver, but behind the scenes, PyMongo connects to multiple nodes of the replica set. The w value can be set at the client level. Andrew says that the w concern can be set at the connection level; he really means client level. It&amp;rsquo;s also important to note that &lt;code&gt;wtimeout&lt;/code&gt; is the amount of time that the database will wait for replication before returning an error on the driver, but that even if the database returns an error due to &lt;code&gt;wtimeout&lt;/code&gt;, the write will not be unwound at the primary and may complete at the secondaries. Hence, writes that return errors to the client due to &lt;code&gt;wtimeout&lt;/code&gt; may in fact succeed, but writes that return success, do in fact succeed. Finally, the video shows the use of an insert command in PyMongo. That call is deprecated and it should have been insert_one.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;w&lt;/code&gt;, &lt;code&gt;j&lt;/code&gt;, and &lt;code&gt;wtimeout&lt;/code&gt; collectively are called write concern, they can be set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;at the time of connection, client level&lt;/li&gt;
&lt;li&gt;at the collection level through the driver&lt;/li&gt;
&lt;li&gt;in the configuration of the replica set, safest from sys admin standpoint&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;j, waiting for journal committed at the primary node only, not waiting for secondary nodes.&lt;/p&gt;

&lt;p&gt;If you set w=1 and j=1, is it possible to wind up rolling back a committed write to the primary on failover? Yes. If the primary goes down before the write propagates to secondaries, it will roll back when it recovers.&lt;/p&gt;

&lt;h2 id=&#34;network-errors&#34;&gt;Network Errors&lt;/h2&gt;

&lt;p&gt;Network errors can cause a failed affirmative response sent back but the write may have succeeded, e.g. a TCP reset. For an insert, it is possible to guard against this since multiple times inserts will cause no harm. Worst case scenario is you get a duplicate key error. The problem is for updates, e.g. a &lt;code&gt;$inc&lt;/code&gt; operation, if you do not know the values, there is no possible way to check whether it succeeded with a network error.&lt;/p&gt;

&lt;p&gt;Generally, when the network is healthy, this type of error is rare. If you want to avoid it at all cost, you can turn all updates into inserts and deletes.&lt;/p&gt;

&lt;h1 id=&#34;replication-mongodb-s-approach-to-fault-tolerance-and-availability&#34;&gt;Replication (MongoDB&amp;rsquo;s Approach to Fault Tolerance and Availability)&lt;/h1&gt;

&lt;p&gt;Replication helps to solve both availability and fault tolerance. A &lt;strong&gt;replica set&lt;/strong&gt; is a set of mongo nodes (mongod) that act together and all mirror each other in terms of data. There is one primary node and the rest are dynamic secondary nodes. Data written to the primary will asynchronously replicate to the secondaries. Application connects to the primary only. If the primary goes down, there will be an election for a new primary all transparent to the application.&lt;/p&gt;

&lt;p&gt;The minimum number of nodes is three.&lt;/p&gt;

&lt;h2 id=&#34;replica-set-elections&#34;&gt;Replica Set Elections&lt;/h2&gt;

&lt;p&gt;Types of replica set nodes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;regular (primary/secondary)&lt;/li&gt;
&lt;li&gt;arbiter, just for election/voting purposes, no data&lt;/li&gt;
&lt;li&gt;delayed, often disaster recovering node(1h behind). Set priority=0 (p=0) and it cannot become a primary node.&lt;/li&gt;
&lt;li&gt;hidden, never primary, p=0, often used for analytics, can vote.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Typically each node has one vote.&lt;/p&gt;

&lt;h2 id=&#34;write-consistency&#34;&gt;Write Consistency&lt;/h2&gt;

&lt;p&gt;MongoDB has strong consistency, vs. some others have eventual consistency. In the default configuration, application reads from and writes to the primary node. You will not read stale data in strong consistency. The writes have to go to the primary. The reads can go to the secondaries for eventual consistency. The lag is not guaranteed since the replication is asynchronous. One reason to do it is to scale the reads to the replica set. When failover occurs (usually under 3 seconds), write cannot complete.&lt;/p&gt;

&lt;p&gt;Eventual consistency might be harder to reason about. Most application servers are stateless, write and read back out and get a different value, then have to reconcile.&lt;/p&gt;

&lt;h2 id=&#34;create-a-replica-set&#34;&gt;Create a Replica Set&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# bash &amp;lt; create_replica_set.sh
#!/usr/bin/env bash
# 3 on a single node so different ports
# --fork so do not have to run each in its own shell

mkdir -p /data/rs1 /data/rs2 /data/rs3
mongod --replSet m101 --logpath &amp;quot;1.log&amp;quot; --dbpath /data/rs1 --port 27017 --oplogSize 64 --fork --smallfiles
mongod --replSet m101 --logpath &amp;quot;2.log&amp;quot; --dbpath /data/rs2 --port 27018 --oplogSize 64 --smallfiles --fork
mongod --replSet m101 --logpath &amp;quot;3.log&amp;quot; --dbpath /data/rs3 --port 27019 --oplogSize 64 --smallfiles --fork
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;$ mongo --port 27018 &amp;lt; init_replica.js

config = { _id: &amp;quot;m101&amp;quot;, members:[
          { _id : 0, host : &amp;quot;localhost:27017&amp;quot;, priority:0, slaveDelay:5},
					// delayed 5 seconds, not primary
          { _id : 1, host : &amp;quot;localhost:27018&amp;quot;},
          { _id : 2, host : &amp;quot;localhost:27019&amp;quot;} ]
};

rs.initiate(config);
rs.status();
rs.conf(); // show the configuration
rs.help(); // replica set commands help
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ mongo --port 27018
MongoDB shell version 2.2.0
connecting to: 127.0.0.1:27018/test
m101:SECONDARY&amp;gt; rs.status()
# will see 3 members two in RECOVERING stateStr, one in PRIMARY.
# Momentarily, one in PRIMARY, two in SECONDARY. Prompt also changes to primary.
m101:PRIMARY&amp;gt; db.people.insert({&#39;name&#39;:&#39;Andrew&#39;})
$ mongo --port 27019
m101:SECONDARY&amp;gt; rs.slaveOk() # allow to read from secondary
m101:SECONDARY&amp;gt; db.people.find()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Normally when you create replicate sets, you would want the &lt;code&gt;mongod&lt;/code&gt;s on different physical servers so there is real fault tolerance.&lt;/p&gt;

&lt;h2 id=&#34;replica-set-internals-i-class-fa-fa-arrow-up-aria-hidden-true-i&#34;&gt;Replica Set Internals &lt;a href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;oplog (operation log?) kept in sync by mongo. The secondaries are constantly reading the oplog of the primary. It&amp;rsquo;s true that the oplog entries originally come from the primary, but secondaries can sync from another secondary, as long as at least there is a chain of oplog syncs that lead back to the primary.&lt;/p&gt;

&lt;p&gt;Use &lt;code&gt;$ ps -ef | grep mongod&lt;/code&gt; to check the mongod processes that are running.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;m101:PRIMARY&amp;gt; use local
m101:PRIMARY&amp;gt; show collections
oplog.rs
startup_log
m101:PRIMARY&amp;gt; db.oplog.rs.find().pretty()
&amp;quot;op&amp;quot; : &amp;quot;i&amp;quot; # insert
&amp;quot;ns&amp;quot; : &amp;quot;test.people&amp;quot; # into test.people
&amp;quot;o&amp;quot; : {_id: ..., name: &amp;quot;Andrew&amp;quot; }
&amp;quot;op&amp;quot; : &amp;quot;c&amp;quot; # create collection
&amp;quot;ns&amp;quot; : &amp;quot;test.$cmd&amp;quot;
&amp;quot;o&amp;quot; : { create:people }
m101:SECONDARY&amp;gt; db.oplog.rs.find().pretty()
# should see exactly the same log as in primary
optime and optimeDate # whether this node is up to date
syncingTo # where it gets its data from
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;oplog is a capped collection, which rolls off at certain times. The oplog needs to be big enough to deal with periods where the secondary can&amp;rsquo;t see the primary. The oplog&amp;rsquo;s size depends on how long you expect there to be a bifurcation of the network and how much data you are writing, how fast the oplog is growing. If the oplog rolls over and the secondary can&amp;rsquo;t get to the primary&amp;rsquo;s oplog, you can still resync the secondary but he has to read the entire database (much slower).&lt;/li&gt;
&lt;li&gt;oplog uses a statement (MongoDB documents) based approach, which allows mixed mode replica sets (flexibility on storage engines or even mongodb versions). And this helps doing (rolling) upgrades in the system.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Replica set election:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ kill 60494 # found by ps primary
# the other shell window already changed prompt within 1s already primary
stateStr : (not reachable/health) # the one killed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;connect-with-java-driver&#34;&gt;Connect with Java Driver&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# after inserting some documents into the primary
replset:PRIMARY&amp;gt; rs.stepdown() # simulate a failover
replset:SECONDARY&amp;gt;  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The older way to initiate a &lt;code&gt;MongoClient&lt;/code&gt; will fail on a failover since it will wait until it connects to a primary before insertion. Instead, pass in &lt;code&gt;Arrays.asList(new ServerAddress(&amp;quot;localhost&amp;quot;, 27017))&lt;/code&gt; will work because the driver can discover the primary through the secondary. This will not work if the process of 27017 was killed.&lt;/p&gt;

&lt;p&gt;The list of mongod servers here is refereed to as a seedlist.&lt;/p&gt;

&lt;p&gt;Bump up log level:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-xml&#34;&gt;&amp;lt;root level=&amp;quot;WARN&amp;quot;&amp;gt;
	&amp;lt;appender-ref ref=&amp;quot;STDOUT&amp;quot;/&amp;gt;
&amp;lt;/root&amp;gt;

&amp;lt;!-- change first line --&amp;gt;

&amp;lt;root level=&amp;quot;INFO&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What to do in the &lt;code&gt;catch&lt;/code&gt; clause when we catch a &lt;code&gt;MongoSocketException&lt;/code&gt;? It depends on the application.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;try insertion again if it is idempotent (contains a specific _id and that the field has a unique index).&lt;/li&gt;
&lt;li&gt;put this message into another system.&lt;/li&gt;
&lt;li&gt;notify a system admin.&lt;/li&gt;
&lt;li&gt;return error to the user.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A robust solution (in python) is to put inserts into a retry loop for 3 tries. If the insertion is successful, it will break out the retry loop. If a &lt;code&gt;AutoReconnect&lt;/code&gt; error occurs, &lt;code&gt;time.sleep(5)&lt;/code&gt; sleep for full 5 seconds and go back to the second try in the retry loop. We need to handle the &lt;code&gt;DuplicateKeyError&lt;/code&gt; since the insert may have succeeded even we got the &lt;code&gt;AutoReconnect&lt;/code&gt; error.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$inc&lt;/code&gt;, &lt;code&gt;$push&lt;/code&gt; operators are not idempotent and may cause issues in scenarios of &lt;code&gt;AutoReconnect&lt;/code&gt; error but the actual insert/update have succeeded. You can&amp;rsquo;t just retry. &lt;code&gt;$set&lt;/code&gt; is idempotent. We can turn &lt;code&gt;$inc&lt;/code&gt; into a &lt;code&gt;find()&lt;/code&gt; plus a &lt;code&gt;$set&lt;/code&gt; and the operation is now idempotent but is no longer atomic (you can lose a vote if two threads try to update at the same time).&lt;/p&gt;

&lt;h2 id=&#34;failover-and-rollback&#34;&gt;Failover and Rollback&lt;/h2&gt;

&lt;p&gt;Even if you set w=1 j=1 on the primary, if the node fails before the write gets synced to the secondaries, when it comes back up it will roll back the writes. One way to avoid it mostly is to set w=majority (wait until the majority of the nodes have the data then the vulnerability does not exist for the most part, small corner cases below).&lt;/p&gt;

&lt;p&gt;While it is true that a replica set will never rollback a write if it was performed with w=majority and that write successfully replicated to a majority of nodes, it is possible that a write performed with w=majority gets rolled back. Here is the scenario: you do write with w=majority and a failover occurs after the write has committed to the primary but before replication completes. You will likely see an exception at the client. An election occurs and a new primary is elected. When the original primary comes back up, it will rollback the committed write. However, from your application&amp;rsquo;s standpoint, that write never completed, so that&amp;rsquo;s ok.&lt;/p&gt;

&lt;h2 id=&#34;read-preference&#34;&gt;Read Preference&lt;/h2&gt;

&lt;p&gt;The driver connects to the primary node and maintains connections to the secondary nodes as well. By default, reads and writes go to the primary. Read preference settings:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;primary&lt;/li&gt;
&lt;li&gt;primary preferred&lt;/li&gt;
&lt;li&gt;secondary, eventually consistency&lt;/li&gt;
&lt;li&gt;secondary preferred&lt;/li&gt;
&lt;li&gt;nearest (in terms of pin time, &amp;lt; 15ms considered nearest, can have a tag set, data center awareness idea)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If read preference is set to secondary only, for the case of primary stepdown, the python code does not have to handle exception.&lt;/p&gt;

&lt;p&gt;One thing to remember is that the driver will check, upon attempting to write, whether or not its write concern is valid. It will error if, for example, w=4 but there are 3 data-bearing replica set members. This will happen quickly in both the Java and pymongo drivers. Reading with an invalid read preference will take longer, but will also result in an error. Be aware, though, that this behavior can vary a little between drivers and between versions.&lt;/p&gt;

&lt;h1 id=&#34;sharding-distributed-mongodb&#34;&gt;Sharding (Distributed MongoDB)&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/mongodb-sharding2.png&#34; alt=&#34;mongodb sharding scheme&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sharding introduces horizontal scalability. Shards split data up from a particular collection. Shards are typically replica sets themselves. Application sends commands through &lt;code&gt;mongos&lt;/code&gt; routers to the shards. For example, an orders collection can be sharded range based with a shard key of order_id. The router will keep maps of key ranges to chunks and mapping of chunks to the shards. If the query does not include a shard key, the query will be scattered to all the shard servers and gather back the answer and respond to the application. Shard key have to be included in inserts.&lt;/p&gt;

&lt;p&gt;Sharding is at a database/collection level. Collections not sharded will sit in the first shard (shard 0). The routers are pretty stateless and are handled similarly to a replica set.&lt;/p&gt;

&lt;p&gt;As of MongoDB 2.4, we also offer hash-based sharding, which offers a more even distribution of data as a function of shard key, at the expense of worse performance for range-based queries.&lt;/p&gt;

&lt;h2 id=&#34;building-a-sharded-environment&#34;&gt;Building a Sharded Environment&lt;/h2&gt;

&lt;p&gt;Probably more of a DBA task. The example will build 3 shards: s0, s1, and s2, each is a replica set with 3 nodes (&lt;code&gt;mongod --shardsvr&lt;/code&gt;); 1 mongos at port 27017 (&lt;code&gt;mognos --configdb&lt;/code&gt;); 3 config servers (&lt;code&gt;mongod --configsvr&lt;/code&gt;) holding information about the way of how data are distributed across the shards (map chunks to shards). There are two ways to shard:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ranged based O(lgN) assuming binary search based&lt;/li&gt;
&lt;li&gt;hash based O(1), O(lgN) worst case, under universal hashing assumption&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Every document must have a shard key that is indexed, but does not have to be unique.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ mongo # mongos at 27017
mongos&amp;gt; sh.status()
# see info about shards: {...}, chunks, .etc
mongos&amp;gt; db.students.explain().find({}).limit(10)
# stage: &amp;quot;SHARD_MERGE&amp;quot;, goes to all three shards
mongos&amp;gt; db.students.explain().find({student_id:1000}).limit(10)
# only goes to s0 shard, IXSCAN
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;implications-of-sharding-on-development&#34;&gt;Implications of Sharding on Development&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;every document needs to include a shard key&lt;/li&gt;
&lt;li&gt;the shard key is immutable&lt;/li&gt;
&lt;li&gt;index that starts with the shard key, cannot be a multikey index&lt;/li&gt;
&lt;li&gt;when doing an update, specify shard key or multi is true&lt;/li&gt;
&lt;li&gt;no shard key means scatter gather operation&lt;/li&gt;
&lt;li&gt;no unique index unless starting with the shard key. There is no way of enforcing the uniqueness of an index if it doesn&amp;rsquo;t include the shard key because it doesn&amp;rsquo;t know whether or not copies exist on different shards. The indexes are on each shard.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Sharding and replication are almost always done together. Usually &lt;code&gt;mongos&lt;/code&gt; is replicated itself typically run on the same box as the application since they are pretty lightweight.&lt;/p&gt;

&lt;h2 id=&#34;choosing-a-shard-key&#34;&gt;Choosing a Shard Key&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Sufficient cardinality, e.g., 3 possible values across 100 shards not good. You can put in a second part of the key with more cardinality.&lt;/li&gt;
&lt;li&gt;Avoid hotspotting in writes, which occurs for anything monotonically increasing (BSON ID, high part is time stamp). First chunk starts with &lt;code&gt;$minkey&lt;/code&gt; and last chunk ends with &lt;code&gt;$maxkey&lt;/code&gt;. It will always get assigned to the highest chunk.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For example, we are sharding on billions of orders and the order_ids are monotonically increasing. So maybe shard on (vendor, order_date) considering the two aspects above. Think about how was the problem naturally parallel? Cannot redo since they are immutable. Needs careful design, testing before commit to one.&lt;/p&gt;

&lt;h1 id=&#34;resources&#34;&gt;Resources&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://university.mongodb.com/courses/M101P/about&#34;&gt;MongoDB University Classes&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/&#34;&gt;MongoDB Docs&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;#&#34;&gt;go to top &lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jessezhuang.github.io/
tags/mongodb/&#34;&gt;Link to the MongoDB tutorial series.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Mongodb Tutorial 1 - Introduction</title>
      <link>http://jessezhuang.github.io/article/mongodb-intro/</link>
      <pubDate>Sun, 26 Jun 2016 19:27:36 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/mongodb-intro/</guid>
      <description>

&lt;p&gt;To run mongo commands from the source of a JavaScript file,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;cat source.js | mongo # or
mongo &amp;lt; source.js # or just
mongo source.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To import/export data,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ mongoimport -d &amp;lt;database&amp;gt; -c &amp;lt;collection&amp;gt; -f &amp;lt;file&amp;gt;
$ mongoimport -d &amp;lt;dababase&amp;gt; -c &amp;lt;collection&amp;gt; &amp;lt; file.json
$ mongoexport -d &amp;lt;dababase&amp;gt; -c &amp;lt;collection&amp;gt; --out file.json
$ mongorestore -d &amp;lt;database&amp;gt; -c &amp;lt;collection&amp;gt; file.bson
# by default writes BSON file to dump/ in current directory
$ mongodump -d &amp;lt;database&amp;gt; -c &amp;lt;collection [--out &amp;lt;path&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;what-is-mongodb&#34;&gt;What is MongoDB?&lt;/h1&gt;

&lt;p&gt;A document based NoSQL database with JSON (javascript object notation) elements. One important advantage is to support common data access patterns with one single query without joins. Actually, MongoDB does not support join, which makes it easier to shard/scale out. Joins and multi-table transactions are difficult to do in parallel, which requires scaling up (expensive single server).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Application Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Mongo shell/driver connects to mongod server process through TCP. The course will build a blog website with MongoDB as the datastore. The java course uses 
&lt;a target=&#34;_blank&#34; href=&#34;http://sparkjava.com/&#34;&gt;SparkJava&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
 and 
&lt;a target=&#34;_blank&#34; href=&#34;http://freemarker.org/&#34;&gt;Freemarker&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
. The python course uses 
&lt;a target=&#34;_blank&#34; href=&#34;http://bottlepy.org/&#34;&gt;Bottle&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
 and its simple template engine. The 
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/ecosystem/drivers/&#34;&gt;drivers&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
 will be mongo java and pymongo.&lt;/p&gt;

&lt;h2 id=&#34;json-and-bson-documents&#34;&gt;JSON and BSON Documents&lt;/h2&gt;

&lt;p&gt;For more details on JSON standard, 
&lt;a target=&#34;_blank&#34; href=&#34;http://www.json.org/&#34;&gt;read here&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
. General format: key value pairs in the form of { key : value}. Keys must be strings followed by colon (:) and the corresponding value. Fields are separated by comma (,). Value types include string, date, number, boolean, array, object, and nested fields (recursive).&lt;/p&gt;

&lt;p&gt;You can find 
&lt;a target=&#34;_blank&#34; href=&#34;http://bsonspec.org/spec.html&#34;&gt;BSON specs here&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
. MongoDB actually stores data in BSON, binary JSON format. MondoDB drivers sends/receives data as BSON. The drivers map BSON to language appropriate data types. BSON is lightweight, traversable (writing, reading, indexing), and efficient (encoding/decoding quickly).&lt;/p&gt;

&lt;p&gt;BSON supports more data types:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;number (byte, int32, int64, double)&lt;/li&gt;
&lt;li&gt;date&lt;/li&gt;
&lt;li&gt;binary&lt;/li&gt;
&lt;li&gt;supports images&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How json documents are encoded as bson:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;//JSON
{ &amp;quot;hello&amp;quot; : &amp;quot;world&amp;quot; }
//BSON
&amp;quot;\x16\x00\x00\x00\x02hello\x00
\x06\x00\x00\x00world\x00\x00&amp;quot;
//length of document, type of value, field length, null terminators .etc
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;installing-mongodb&#34;&gt;Installing MongoDB&lt;/h2&gt;

&lt;p&gt;Downdload mongodb 
&lt;a target=&#34;_blank&#34; href=&#34;https://www.mongodb.com/download-center&#34;&gt;from here&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
. A tip for the linux versions: after extracting the tarballs, you could simply copy the executables from the bin folder into your virtualenv&amp;rsquo;s bin &lt;code&gt;path/to/venv/bin&lt;/code&gt; folder, assuming you are using pymonogo in a virtualenv with python 2. Alternatively you can copy to /usr/local/bin as suggested for a global use.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ tar xvf mongodb-linux-x86_64-ubuntu1404-3.2.6.tgz
$ cp mongodb-linux-x86_64-ubuntu1404-3.2.6/bin/* path/to/venv/bin/
$ cd path/to/venv/
$ source bin/activate
$ mkdir -p /data/db
$ sudo chmod 777 /data
$ sudo chmod 777 /data/db
(venv) $ mongod
# in another terminal window
(venv) $ mongo
MongoDB shell version: 3.2.6
connecting to: test
&amp;gt; db.names.insert({&#39;name&#39;:&#39;Andrew Erlicson&#39;})
WriteResult({ &amp;quot;nInserted&amp;quot; : 1 })
&amp;gt; db.names.find()
{ &amp;quot;_id&amp;quot; : ObjectId(&amp;quot;5778642550b9dd3f38d82b4e&amp;quot;), &amp;quot;name&amp;quot; : &amp;quot;Andrew Erlicson&amp;quot; }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On Windows, download the msi installer and install as directed. Add mongodb bin (C:\Program Files\MongoDB\Server\3.2\bin) folder to PATH.&lt;/p&gt;

&lt;h1 id=&#34;crud-operations-i-class-fa-fa-arrow-up-aria-hidden-true-i&#34;&gt;CRUD Operations &lt;a href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;In mongo shell,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; help //list of mongo commands
&amp;gt; show dbs
local 0.070GB
test 0.001GB
&amp;gt; show collections
names
&amp;gt; // video.movies refers to video database movies collection
&amp;gt; db.names.find() // global variable db refers to current database
&amp;gt; use video // mongodb creates database in lazy fashion when data inserted
&amp;gt; db.movies.insertOne({&amp;quot;title&amp;quot;: &amp;quot;Jaws&amp;quot;, &amp;quot;year&amp;quot;: 1975, &amp;quot;imdb&amp;quot;: &amp;quot;tt0073195&amp;quot;})
{ &amp;quot;acknowledged&amp;quot;:true, &amp;quot;insertId&amp;quot;:ObjectId(&amp;quot;5778b5782430a299a54686b5&amp;quot;)}
// mongodb will add _id field if not specified
&amp;gt; db.movies.find()
{ &amp;quot;_id&amp;quot; : ObjectId(&amp;quot;5778b5782430a299a54686b5&amp;quot;),
  &amp;quot;title&amp;quot; : &amp;quot;Jaws&amp;quot;, &amp;quot;year&amp;quot; : 1975, &amp;quot;imdb&amp;quot; : &amp;quot;tt0073195&amp;quot; }
&amp;gt; db.movies.find({}).pretty()
{
  &amp;quot;_id&amp;quot; : ObjectId(&amp;quot;5778b5782430a299a54686b5&amp;quot;),
  &amp;quot;title&amp;quot; : &amp;quot;Jaws&amp;quot;,
  &amp;quot;year&amp;quot; : 1975,
  &amp;quot;imdb&amp;quot; : &amp;quot;tt0073195&amp;quot;
}
&amp;gt; var c = db.movies.find() // returns a cursor
&amp;gt; c.hasNext()
true
&amp;gt; c.next()
{
  &amp;quot;_id&amp;quot; : ObjectId(&amp;quot;5778b5782430a299a54686b5&amp;quot;),
  &amp;quot;title&amp;quot; : &amp;quot;Jaws&amp;quot;,
  &amp;quot;year&amp;quot; : 1975,
  &amp;quot;imdb&amp;quot; : &amp;quot;tt0073195&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;example-project-blog-site&#34;&gt;Example Project Blog Site&lt;/h1&gt;

&lt;p&gt;Relational model for the blog. We will need six tables fully denormalized.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;posts&lt;/th&gt;
&lt;th&gt;comments&lt;/th&gt;
&lt;th&gt;tags&lt;/th&gt;
&lt;th&gt;post-tags&lt;/th&gt;
&lt;th&gt;post-comments&lt;/th&gt;
&lt;th&gt;authors&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;post_id&lt;/td&gt;
&lt;td&gt;comment_id&lt;/td&gt;
&lt;td&gt;tag_id&lt;/td&gt;
&lt;td&gt;post_id&lt;/td&gt;
&lt;td&gt;post_id&lt;/td&gt;
&lt;td&gt;author_id&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;author_id&lt;/td&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;tag_id&lt;/td&gt;
&lt;td&gt;comment_id&lt;/td&gt;
&lt;td&gt;username&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;title&lt;/td&gt;
&lt;td&gt;comment&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;password&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;post&lt;/td&gt;
&lt;td&gt;email&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;date&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In order to show a blog post with comments and tags, we need to join all the six tables.&lt;/p&gt;

&lt;p&gt;As for the document model, for a post JSON document in posts collection:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{
  title : &amp;quot;free online tutorial&amp;quot;,
  body : &amp;quot;......&amp;quot;,
  author : &amp;quot;erlicson&amp;quot;,
  date : ISODate(......),
  comments : [ { name: &amp;quot;joe biden&amp;quot;, email : &amp;quot;joe@mongodb.org&amp;quot;, comment:&amp;quot;...&amp;quot; },
              {.....}, {.....}
             ],
  tags: [&amp;quot;cycling&amp;quot;, &amp;quot;education&amp;quot;, &amp;quot;startups&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will need a authors collection with username as primary key:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;{
  _id : &amp;quot;erlicosn&amp;quot;,
  password : &amp;quot;...&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The data is hierarchical. If email is missing from any comment, it does not have to be there. You can leave it out. MongoDB is schemaless and flexible about that.We only need 1 collection, the post collection to display a blog post.&lt;/p&gt;

&lt;h1 id=&#34;introduction-to-schema-design&#34;&gt;Introduction to Schema Design&lt;/h1&gt;

&lt;p&gt;&amp;ldquo;To embed or not embed, that is the question.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;With relational database, you consider normal forms (3rd, 4th, Boyce-Codd) and dependencies. Maybe start with 3rd normal form and combine a few things.&lt;/p&gt;

&lt;p&gt;With mongodb, how do you know when to embed? For example, to embed the tags and comments into the posts collection. The answer is that they are typically accessed at the same time. It&amp;rsquo;s very rare to access a tag independently of accessing a post. The comment itself does not apply to more than one post.&lt;/p&gt;

&lt;p&gt;An operation like changing a tag named &amp;ldquo;cycling&amp;rdquo; to &amp;ldquo;biking&amp;rdquo; for the whole site would be easier in relational world but it is an unusual change to make, something you are not changing all the time.&lt;/p&gt;

&lt;p&gt;Another practical concern is the document size. In mongodb, documents cannot be more than 16 MB.&lt;/p&gt;

&lt;h1 id=&#34;mongodb-basics-cheatsheet&#34;&gt;MongoDB Basics Cheatsheet&lt;/h1&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;command&lt;/th&gt;
&lt;th&gt;effect&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;db.runCommand{dropDatabase:1}&lt;/td&gt;
&lt;td&gt;drop the current database, deleting associated files&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;db.dropDatabase()&lt;/td&gt;
&lt;td&gt;same as above&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;db.runCommand{drop:collname}&lt;/td&gt;
&lt;td&gt;delete &lt;code&gt;collname&lt;/code&gt; collection from the current database and associated indexes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;db.collname.drop()&lt;/td&gt;
&lt;td&gt;same as above&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;show dbs&lt;/td&gt;
&lt;td&gt;show all databases&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;show collections&lt;/td&gt;
&lt;td&gt;show all collections in current database&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;use dbname&lt;/td&gt;
&lt;td&gt;switch to &lt;code&gt;dbname&lt;/code&gt; database&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&#34;resources&#34;&gt;Resources&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://university.mongodb.com/courses/M101P/about&#34;&gt;MongoDB University Classes&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/&#34;&gt;MongoDB Docs&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;#&#34;&gt;back to top &lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jessezhuang.github.io/
tags/mongodb/&#34;&gt;Link to the MongoDB tutorial series.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MongoDB Tutorial 5 - Aggregation Framework</title>
      <link>http://jessezhuang.github.io/article/mongodb-aggregation-framework/</link>
      <pubDate>Sun, 26 Jun 2016 14:55:57 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/mongodb-aggregation-framework/</guid>
      <description>

&lt;p&gt;The aggregation framework has its roots in SQL&amp;rsquo;s world of &lt;code&gt;groupby&lt;/code&gt; clause.&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;Example used: imagine a SQL table of products.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;category&lt;/th&gt;
&lt;th&gt;manufacture&lt;/th&gt;
&lt;th&gt;price&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ipad&lt;/td&gt;
&lt;td&gt;tablet&lt;/td&gt;
&lt;td&gt;Apple&lt;/td&gt;
&lt;td&gt;499&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;nexus s&lt;/td&gt;
&lt;td&gt;cellphone&lt;/td&gt;
&lt;td&gt;Samsung&lt;/td&gt;
&lt;td&gt;350&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To get number of products from each manufacture with SQL,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select manufacture, count(*) from products
  group by manufacture;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with mongodb,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; use agg
&amp;gt; db.products.aggregate([ // array
  {$group:
    {
      _id:&amp;quot;$manufacturer&amp;quot;, // creating new collection
      num_products:{$sum:1}
    } // a series of upserts
  }
])
{&amp;quot;_id&amp;quot; : &amp;quot;Amazon&amp;quot;, &amp;quot;num_products&amp;quot; : 2}
{&amp;quot;_id&amp;quot; : &amp;quot;Sony&amp;quot;, &amp;quot;num_products&amp;quot; : 1}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To do compound grouping with SQL,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select manufacturer, category, count(*) from
  products group by manufacturer, category
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with mongodb,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.products.aggregate([
  {$group:
    {
      // _id can be a complex document, just have to be unique
      _id:{&amp;quot;manufacturer&amp;quot;:&amp;quot;$manufacturer&amp;quot;,&amp;quot;category&amp;quot;:&amp;quot;category&amp;quot;},
      num_products:{$sum:1}
    }
  }
])
{&amp;quot;_id&amp;quot; : {&amp;quot;manufacturer&amp;quot;:&amp;quot;Amazon&amp;quot;, &amp;quot;category&amp;quot;:&amp;quot;Tablets&amp;quot;}, &amp;quot;num_products&amp;quot; : 2}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/manual/reference/sql-aggregation-comparison/&#34;&gt;SQL to Aggregation Mapping Chart&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
.&lt;/p&gt;

&lt;p&gt;One can group on &lt;code&gt;_id:null&lt;/code&gt; to aggregate every single document such as counting or summing.&lt;/p&gt;

&lt;h1 id=&#34;aggregation-pipeline&#34;&gt;Aggregation Pipeline&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/mongodb-aggregation-pipeline.png&#34; alt=&#34;mongodb-aggregation-pipeline&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;pipeline stages&lt;/th&gt;
&lt;th&gt;job&lt;/th&gt;
&lt;th&gt;documents handling&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$project&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;reshape documents, select out fields potentially deep in hierarchy&lt;/td&gt;
&lt;td&gt;1:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$match&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;filter out&lt;/td&gt;
&lt;td&gt;n:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$group&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;aggregate&lt;/td&gt;
&lt;td&gt;n:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$sort&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;sorting&lt;/td&gt;
&lt;td&gt;1:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$skip&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;skips&lt;/td&gt;
&lt;td&gt;n:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$limit&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;limit&lt;/td&gt;
&lt;td&gt;n:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$unwind&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;normalize, flatten data before grouping&lt;/td&gt;
&lt;td&gt;1:n&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$out&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;redirect output&lt;/td&gt;
&lt;td&gt;1:1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$redact&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;security related&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;$geonear&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;location based searching&lt;/td&gt;
&lt;td&gt;n:1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code&gt;$unwind&lt;/code&gt; example: &lt;code&gt;tags:[red, blue]&lt;/code&gt; unwinds to &lt;code&gt;tag:red&lt;/code&gt; and &lt;code&gt;tag:blue&lt;/code&gt;, expanding the number of documents.&lt;/p&gt;

&lt;h2 id=&#34;more-operators-with-examples-i-class-fa-fa-arrow-up-aria-hidden-true-i&#34;&gt;More Operators with Examples &lt;a href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The &lt;code&gt;$sum&lt;/code&gt; operator:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.products.aggregate([ // array
  {$group:
    {
      _id:{&amp;quot;maker&amp;quot;:&amp;quot;$manufacturer&amp;quot;}, // creating new collection
      sum_prices:{$sum:&amp;quot;$price&amp;quot;}
    } // a series of upserts
  }
])
{&amp;quot;_id&amp;quot; : {&amp;quot;maker&amp;quot;:&amp;quot;Amazon&amp;quot;}, &amp;quot;sum_prices&amp;quot; : 328}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;$avg&lt;/code&gt; operator:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.products.aggregate([ // array
  {$group:
    {
      _id:{&amp;quot;category&amp;quot;:&amp;quot;$category&amp;quot;}, // creating new collection
      avg_prices:{$avg:&amp;quot;$price&amp;quot;}
    } // a series of upserts
  }
])
{&amp;quot;_id&amp;quot; : {&amp;quot;category&amp;quot;:&amp;quot;Tablets&amp;quot;}, &amp;quot;avg_prices&amp;quot; : 396.42714}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;$addToSet&lt;/code&gt; operator without counterpart in SQL:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.products.aggregate([ // array
  {$group:
    {
      _id:{&amp;quot;maker&amp;quot;:&amp;quot;$manufacturer&amp;quot;}, // creating new collection
      categories:{$addToSet:&amp;quot;$category&amp;quot;}
    } // a series of upserts
  }
])
{&amp;quot;_id&amp;quot; : {&amp;quot;maker&amp;quot;:&amp;quot;Apple&amp;quot;}, &amp;quot;categories&amp;quot; : [&amp;quot;Laptops&amp;quot;, &amp;quot;Tablets&amp;quot;]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;$push&lt;/code&gt; operator:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.products.aggregate([ // array
  {$group:
    {
      _id:{&amp;quot;maker&amp;quot;:&amp;quot;$manufacturer&amp;quot;}, // creating new collection
      categories:{$push:&amp;quot;$category&amp;quot;}
    } // a series of upserts
  }
])
{&amp;quot;_id&amp;quot; : {&amp;quot;maker&amp;quot;:&amp;quot;Apple&amp;quot;}, &amp;quot;categories&amp;quot; :
  [&amp;quot;Tablets&amp;quot;, &amp;quot;Tablets&amp;quot;, &amp;quot;Tablets&amp;quot;, &amp;quot;Laptops&amp;quot;]}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;$max&lt;/code&gt; and &lt;code&gt;$min&lt;/code&gt; operators:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.products.aggregate([ // array
  {$group:
    {
      _id:{&amp;quot;maker&amp;quot;:&amp;quot;$manufacturer&amp;quot;}, // creating new collection
      maxprice:{$max:&amp;quot;$price&amp;quot;}
    } // a series of upserts
  }
])
{&amp;quot;_id&amp;quot; : {&amp;quot;maker&amp;quot;:&amp;quot;Apple&amp;quot;}, &amp;quot;maxprice&amp;quot; : 699 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;$project&lt;/code&gt; phase/stage: you can remove, add, reshape keys, use simple functions on keys such as &lt;code&gt;$toUpper&lt;/code&gt;, &lt;code&gt;$toLower&lt;/code&gt;, &lt;code&gt;$add&lt;/code&gt;, &lt;code&gt;$multiply&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.products.aggregate([
  {$project:
    {
      _id:0,
      &#39;maker&#39;: {$toLower:&amp;quot;$manufacturer&amp;quot;},
      &#39;details&#39;: {&#39;category&#39;: &amp;quot;$category&amp;quot;,
        &#39;price&#39; : {&amp;quot;$multiply&amp;quot;:[&amp;quot;$price&amp;quot;,10]}
      },
      &#39;item&#39;:&#39;$name&#39;
    }
  }
])
{&amp;quot;maker&amp;quot;:&amp;quot;amazon&amp;quot;, &amp;quot;details&amp;quot;:{&amp;quot;category&amp;quot;:&amp;quot;Tablets&amp;quot;, &amp;quot;price&amp;quot;:1990},
  &amp;quot;item&amp;quot;:&amp;quot;Kindle Fire&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;$match&lt;/code&gt; phase. One thing to note about $match (and $sort) is that 
&lt;a target=&#34;_blank&#34; href=&#34;http://docs.mongodb.org/manual/core/aggregation-pipeline/?_ga=1.241498631.463502008.1466893758&#34;&gt;they can use indexes&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
, but only if done at the beginning of the aggregation pipeline. 
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/manual/tutorial/aggregation-zip-code-data-set/&#34;&gt;Example zips collection.&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.zips.aggregate([
  {$match:
    {
      state:&amp;quot;NY&amp;quot;
    }
  },
  {$group:
    {
      _id: &amp;quot;$city&amp;quot;,
      population: {$sum:&amp;quot;$pop&amp;quot;},
      zip_codes: {$addToSet: &amp;quot;$_id&amp;quot;}
    }
  },
  {$project:
    {
      _id: 0,
      city: &amp;quot;$_id&amp;quot;,
      population: 1,
      zip_codes:1
    }
  },
  {$sort:
    {population:-1}
  },
  {$skip:10},
  {$limit:5}
])
{&amp;quot;population&amp;quot;:9743, &amp;quot;zip_codes&amp;quot;:[96162, 96161], &amp;quot;city&amp;quot;:&amp;quot;TRUCKEE&amp;quot;}
// order of fields not retained
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$sort&lt;/code&gt; operator. The aggregation framework supports both memory (default, 100 MB limit for each pipeline stage unless allowing disk) and disk based sorting. Sorting can be done before or after the grouping stage.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$skip&lt;/code&gt; and &lt;code&gt;$limit&lt;/code&gt; works similarly in &lt;code&gt;find()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$unwind&lt;/code&gt; operator: it&amp;rsquo;s not easy to group on the array elements (prejoined data) so we need to flatten (unjoin, data explosion) the array.&lt;/p&gt;

&lt;p&gt;To count how many posts were attached to each tag in the blog,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;use blog;
db.posts.aggregate([
    /* unwind by tags */
  {&amp;quot;$unwind&amp;quot;:&amp;quot;$tags&amp;quot;},
    /* now group by tags, counting each tag */
  {&amp;quot;$group&amp;quot;:
    {&amp;quot;_id&amp;quot;:&amp;quot;$tags&amp;quot;,
    &amp;quot;count&amp;quot;:{$sum:1}
    }
  },
  /* sort by popularity */
  {&amp;quot;$sort&amp;quot;:{&amp;quot;count&amp;quot;:-1}},
  /* show me the top 10 */
  {&amp;quot;$limit&amp;quot;: 10},
  /* change the name of _id to be tag */
  {&amp;quot;$project&amp;quot;:
    {_id:0,
      &#39;tag&#39;:&#39;$_id&#39;,
      &#39;count&#39; : 1
    }
  }
])
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;admonition note&#34;&gt;
&lt;p class=&#34;admonition-title&#34;&gt;To reverse $unwind&lt;/p&gt;
&lt;p&gt;You can use $push to reverse the effects of an $unwind. If the array elements were unique, $addToSet will also do the job.&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&#34;more-advanced-aggregation-examples&#34;&gt;More Advanced Aggregation Examples&lt;/h2&gt;

&lt;h3 id=&#34;double-grouping-i-class-fa-fa-arrow-up-aria-hidden-true-i&#34;&gt;Double Grouping &lt;a href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;For a collection of student grades like below:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{ &amp;quot;_id&amp;quot; : { &amp;quot;$oid&amp;quot; : &amp;quot;50b59cd75bed76f46522c34e&amp;quot; },
  &amp;quot;student_id&amp;quot; : 0, &amp;quot;class_id&amp;quot; : 2,
  &amp;quot;scores&amp;quot; : [ { &amp;quot;type&amp;quot; : &amp;quot;exam&amp;quot;, &amp;quot;score&amp;quot; : 57.92947112575566 },
    { &amp;quot;type&amp;quot; : &amp;quot;quiz&amp;quot;, &amp;quot;score&amp;quot; : 21.24542588206755 },
    { &amp;quot;type&amp;quot; : &amp;quot;homework&amp;quot;, &amp;quot;score&amp;quot; : 68.19567810587429 },
    { &amp;quot;type&amp;quot; : &amp;quot;homework&amp;quot;, &amp;quot;score&amp;quot; : 67.95019716560351 },
    { &amp;quot;type&amp;quot; : &amp;quot;homework&amp;quot;, &amp;quot;score&amp;quot; : 18.81037253352722 }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We want to figure out the average class grade for each class,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.grades.aggregate([
    {&#39;$group&#39;:{_id:{class_id:&amp;quot;$class_id&amp;quot;, student_id:&amp;quot;$student_id&amp;quot;},
      &#39;average&#39;:{&amp;quot;$avg&amp;quot;:&amp;quot;$score&amp;quot;}}
    }, // pipe to a secondary grouping stage
    {&#39;$group&#39;:{_id:&amp;quot;$_id.class_id&amp;quot;, &#39;average&#39;:{&amp;quot;$avg&amp;quot;:&amp;quot;$average&amp;quot;}}}
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$first&lt;/code&gt; and &lt;code&gt;$last&lt;/code&gt;, example: find city with largest population in each state.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;b.zips.aggregate([
  /* get the population of every city in every state */
  {$group:
    {
      _id: {state:&amp;quot;$state&amp;quot;, city:&amp;quot;$city&amp;quot;},
      population: {$sum:&amp;quot;$pop&amp;quot;},
    }
  },
  /* sort by state, population */
  {$sort:
    {&amp;quot;_id.state&amp;quot;:1, &amp;quot;population&amp;quot;:-1}
  },
  /* group by state, get the first item in each group */
  {$group:
    {
      _id:&amp;quot;$_id.state&amp;quot;,
      city: {$first: &amp;quot;$_id.city&amp;quot;},
      population: {$first:&amp;quot;$population&amp;quot;}
    }
  },
  /* now sort by state again */
  {$sort:
   {&amp;quot;_id&amp;quot;:1}
  }
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$out&lt;/code&gt; redirects the output to a new collection, write over, no appending, considering a games collection with documents structured like,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;{
  &amp;quot;_id&amp;quot;:ObjectId(&amp;quot;53684890&amp;quot;),
  first_name: &amp;quot;Jerzy&amp;quot;,
  last_name: &amp;quot;Fischer&amp;quot;,
  points: 3,
  moves: [1,2,5]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To summarize each person&amp;rsquo;s points,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.games.aggregate([
  {$group:
    {_id:{first_name:&amp;quot;$first_name&amp;quot;, last_name:&amp;quot;$last_name&amp;quot;},
    points:{$sum:&amp;quot;$points&amp;quot;}
    }
  },
  {$out:&amp;quot;summary_results&amp;quot;}
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the &lt;code&gt;_id&lt;/code&gt; field of the redirected output must be unique, the operations below will not succeed and leave the &lt;code&gt;summary_results&lt;/code&gt; collection untouched.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.games.aggregate([
  {$unwind:&amp;quot;moves&amp;quot;},
  {$out:&amp;quot;summary_results&amp;quot;}
])
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;double-unwind&#34;&gt;Double &lt;code&gt;$unwind&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;Create a Cartesian product of the two or more arrays.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.inventory.aggregate([
  {$unwind: &amp;quot;$sizes&amp;quot;},
  {$unwind: &amp;quot;$colors&amp;quot;},
  {$group:
    {
      &#39;_id&#39;: {&#39;size&#39;:&#39;$sizes&#39;, &#39;color&#39;:&#39;$colors&#39;},
      &#39;count&#39; : {&#39;$sum&#39;:1}
    }
  }
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To reverse with &lt;code&gt;$addToSet&lt;/code&gt; in one stage since array elements were unique,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.inventory.aggregate([
  {$unwind: &amp;quot;$sizes&amp;quot;},
  {$unwind: &amp;quot;$colors&amp;quot;},
  {$group:
    {
      &#39;_id&#39;: &amp;quot;$name&amp;quot;,
      &#39;sizes&#39;: {$addToSet: &amp;quot;$sizes&amp;quot;},
      &#39;colors&#39;: {$addToSet: &amp;quot;$colors&amp;quot;},
    }
  }
])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To reverse with &lt;code&gt;$push&lt;/code&gt;,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.inventory.aggregate([
  {$unwind: &amp;quot;$sizes&amp;quot;},
  {$unwind: &amp;quot;$colors&amp;quot;},
  /* create the color array */
  {$group:
    {
      &#39;_id&#39;: {name:&amp;quot;$name&amp;quot;,size:&amp;quot;$sizes&amp;quot;},
      &#39;colors&#39;: {$push: &amp;quot;$colors&amp;quot;},
    }
  },
  /* create the size array */
  {$group:
    {
      &#39;_id&#39;: {&#39;name&#39;:&amp;quot;$_id.name&amp;quot;,
      &#39;colors&#39; : &amp;quot;$colors&amp;quot;},
      &#39;sizes&#39;: {$push: &amp;quot;$_id.size&amp;quot;}
    }
  },
  /* reshape for beauty */
  {$project:
    {
      _id:0,
      &amp;quot;name&amp;quot;:&amp;quot;$_id.name&amp;quot;,
      &amp;quot;sizes&amp;quot;:1,
      &amp;quot;colors&amp;quot;: &amp;quot;$_id.colors&amp;quot;
    }
  }
])
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;full-text-search-and-aggregation-i-class-fa-fa-arrow-up-aria-hidden-true-i&#34;&gt;Full Text Search and Aggregation &lt;a href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&amp;ldquo;Two great taste that go great together.&amp;rdquo; - &lt;a href=&#34;https://twitter.com/erlichson?lang=en&#34;&gt;Andrew Erlichson&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.sentences.aggregate([
  {$match:{$text:{$search:&amp;quot;tree rat&amp;quot;}}},// must appear first
  // one full text search per collection, no need to specify
  {$sort:{score:{$meta:&amp;quot;textScore&amp;quot;}}},
  {$project:{words:1, _id:0}}
])
{&amp;quot;words&amp;quot;:&amp;quot;rat shrub granite.&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;$text&lt;/code&gt; is only allowed in the $match stage of the aggregation pipeline and must be the first stage of the aggregation pipeline.&lt;/p&gt;

&lt;h3 id=&#34;aggregation-with-java-driver&#34;&gt;Aggregation with Java driver&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class ZipCodeAggregationTest {
  public static void main (Strng[] args) {
    MongoClient client = new MongoClient();
    MongoDatabase database = client.getDatabase(&amp;quot;course&amp;quot;);
    MongoCollection&amp;lt;Document&amp;gt; collection = database.getCollection(&amp;quot;zipcodes&amp;quot;);

    // verbose
    // List&amp;lt;Document&amp;gt; pipeline = Arrays.asList(new Document(&amp;quot;$group&amp;quot;,
    //   new Document(&amp;quot;_id&amp;quot;, &amp;quot;$state&amp;quot;).append(&amp;quot;totalPop&amp;quot;, new Document(
    //     &amp;quot;$sum&amp;quot;, &amp;quot;$pop&amp;quot;))), new Document(&amp;quot;$match&amp;quot;, new Document(&amp;quot;totalPop&amp;quot;,
    //       new Document(&amp;quot;$gte&amp;quot;, 10000000))));

    List&amp;lt;Bson&amp;gt; pipeline = Arrays.asList(Aggregates.group(&amp;quot;$state&amp;quot;, Accumulators.sum(&amp;quot;totalPop&amp;quot;,
      &amp;quot;$pop&amp;quot;)), Aggregates.match(gte(&amp;quot;totalPop&amp;quot;, 10000000)));

    List&amp;lt;Document&amp;gt; pipeline2 = Arrays.asList(Document.parse(
      &amp;quot;{ $group: { _id: \&amp;quot;$state\&amp;quot;, totalPop: { $sum: \&amp;quot;$pop\&amp;quot; } } }&amp;quot;),
      Document.parse(&amp;quot;{ $match: { totalPop: { $gte: 1010001000 } } }&amp;quot;));

    List&amp;lt;Document&amp;gt; results = collection.aggregate(pipeline).
      into(new ArrayList&amp;lt;Document&amp;gt;());
    // List&amp;lt;Document&amp;gt; results = collection.find().into(new ArrayList&amp;lt;Document&amp;gt;());

    for (Document cur : results) {
      System.out.println(cur.toJson());
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;aggregation-options&#34;&gt;Aggregation Options&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;explain&lt;/code&gt; gets the query plan if we ran it, useful in optimization.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;allowDiskUse&lt;/code&gt; allows use of hard drive for intermediate stages. Any stage is limited to 100 MB of memory use and will fail if exceeded. Certain stages like projection run the documents through and don&amp;rsquo;t use a lot of memory.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cursor&lt;/code&gt; allows cursor use and specify cursor size.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;use agg
db.zips.aggregate(
  [{$group:{_id:&amp;quot;$state&amp;quot;, population:{$sum:&amp;quot;$pop&amp;quot;}}}],
  {explain:true},
  {allowDiskUse:true}
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Two forms of aggregation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;aggregate([stage1, stage2, ...])&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aggregate(stage1, stage2, ...)&lt;/code&gt; cannot add options&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Prior to the release of the 3.0 pymongo driver, you would get a document for aggregation queries by default (the aggregation result is limited by the 16 Mb size), though you had the option of getting back a cursor if you were working with MongoDB 2.6.0+, and your pymongo version was 2.6.0+. Starting with the release of the 3.0 pymongo driver, however the aggregation pipeline queries using the driver will now return a cursor by default.&lt;/p&gt;

&lt;p&gt;The mongo shell returns a cursor by default starting 2.6.0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pymongo
connection = pymongo.MongoClient()
db = connection.agg

result = db.zips.aggregate([{&#39;$group&#39;:{&#39;_id&#39;:&#39;state&#39;,
  &#39;population&#39;:{&#39;$sum&#39;:&#39;$pop&#39;}}}])

print result
# &amp;lt;pymongo.command_cursor.CommandCursor object at 0x7f62829f5210&amp;gt; in 3.2.6

# piror to 3.0
result = db.zips.aggregate([{&#39;$group&#39;:{&#39;_id&#39;:&#39;state&#39;,
    &#39;population&#39;:{&#39;$sum&#39;:&#39;$pop&#39;}}}], cursor={}, allowDiskUse=True)

for doc in result:
    print doc
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;# prior to 3.0
{u&#39;ok&#39;:1.0, u&#39;result&#39; : [array of resulted documents]}
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;limitations-of-aggregation-framework&#34;&gt;Limitations of Aggregation framework&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;100 MB limit for pipeline stages, &lt;code&gt;allowDiskUse&lt;/code&gt; to get around.&lt;/li&gt;
&lt;li&gt;16 MB limit if you decide to return the result as a single document, set &lt;code&gt;cursor&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;In a sharded system, stages like &lt;code&gt;$group&lt;/code&gt;, &lt;code&gt;$sort&lt;/code&gt; will bring back the results to the first shard. Stages like &lt;code&gt;$match&lt;/code&gt; and &lt;code&gt;$project&lt;/code&gt; can go in parallel. Aggregation in mongodb is an interface to map/reduce jobs. Alternatively, get the data out of mongodb using the hadoop connector and use Hadoop map/reduce. There is a map/reduce functionality built into mongodb that is not recommended.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/mongodb-limitation.png&#34; alt=&#34;mongodb sharded system limitation&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;resources&#34;&gt;Resources&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://university.mongodb.com/courses/M101P/about&#34;&gt;MongoDB University Classes&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/&#34;&gt;MongoDB Docs&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;#&#34;&gt;go to top &lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jessezhuang.github.io/
tags/mongodb/&#34;&gt;Link to the MongoDB tutorial series.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ubuntu Tips and Tricks</title>
      <link>http://jessezhuang.github.io/article/ubuntu/</link>
      <pubDate>Fri, 24 Jun 2016 23:37:47 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/ubuntu/</guid>
      <description>

&lt;p&gt;Ubuntu version is 14.04 LTS running as a guest OS in Oracle VirtualBox 5. For VirtualBox related issues, see &lt;a href=&#34;http://jessezhuang.github.io/
article/virtualbox-tips/&#34;&gt;http://jessezhuang.github.io/
article/virtualbox-tips/&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;performance-monitoring&#34;&gt;Performance Monitoring&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;top&lt;/code&gt; from command line&lt;/li&gt;
&lt;li&gt;&lt;code&gt;System Monitor&lt;/code&gt; application installed by default.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;screen-capture&#34;&gt;Screen Capture&lt;/h2&gt;

&lt;p&gt;Application &lt;code&gt;Screenshot&lt;/code&gt; installed by default. Can take screenshot of whole screen, current window, or selected area. Similar to &amp;ldquo;Snipping Tool&amp;rdquo; in Windows. To run this tool from the shell, use &lt;code&gt;gnome-screeshot -i&lt;/code&gt; for interactive window specified with mouse, &lt;code&gt;gnome-screenshot -help&lt;/code&gt; for other options.&lt;/p&gt;

&lt;h2 id=&#34;lxde-desktop-environment&#34;&gt;LXDE Desktop Environment&lt;/h2&gt;

&lt;p&gt;LXDE is a much lighter desktop environment (DE) and uses much less memory versus unityand is the standard DE in Lubuntu.&lt;/p&gt;

&lt;h3 id=&#34;fix-lxde-pcmanfm-open-current-folder-in-terminal&#34;&gt;Fix LXDE PCMANFM Open Current Folder in Terminal&lt;/h3&gt;

&lt;p&gt;PCMANFM 1.2.0 is the default file manager used in LXDE which has a built in functionality to open a terminal window at the directory that you are currently browsing with a convenient shortcut of F4. It uses gnome terminal. The problem is the opened terminal window is totally black. The problem is the default profile is using black text on black background.&lt;/p&gt;

&lt;p&gt;In the opened gnome terminal, select from menu bar Edit - Profile Preferences, Colors tab, uncheck &amp;ldquo;use colors from system theme&amp;rdquo;, select a built-in theme or your customized theme. I used white on black built-in theme.&lt;/p&gt;

&lt;p&gt;With LXDE, the ubuntu 14.04LTS system is using about 240 Mb of ram at start up with pacmanfm using a little over 10 Mb. Comparing to unity, about 800 Mb of ram at start up with about 200 Mb for compiz. A lot of times compiz can ramp up to 500 Mb of ram. There is another option Openbox DE, the default is just a blank screen where you would have to right click to pop up the menu.The ram usage is a little less but you would have to customize the menu for it to be really user friendly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux Cheatsheets</title>
      <link>http://jessezhuang.github.io/article/linux-cheatsheet/</link>
      <pubDate>Fri, 24 Jun 2016 14:56:13 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/linux-cheatsheet/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/linus-penguin.jpg&#34; alt=&#34;Linus Penguin Quote&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;linux-commands-cheatsheet&#34;&gt;Linux Commands Cheatsheet&lt;/h1&gt;

&lt;h2 id=&#34;files-related&#34;&gt;Files Related&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;ls - list directory contents

SYNOPSIS
       ls [OPTION]... [FILE]...
       -a, --all
              do not ignore entries starting with .    
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;examples&lt;/th&gt;
&lt;th&gt;effects&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ls -la&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;list all file/directories including hidden in long list form&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;ls -ld&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;list directory only in list form&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;du - estimate file space usage
SYNOPSIS
  du [OPTION]...  [FILE]...
  -c, --total
              produce a grand total
  -h, --human-readable
              print sizes in human readable format (e.g., 1K 234M 2G)
  -s, --summarize
              display only a total for each argument
  -a, --all
                write counts for all files, not just directories
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;examples&lt;/th&gt;
&lt;th&gt;effects&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;du -sch  folder/&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;folder/&lt;/code&gt; size&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;du -sh *&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;sizes of all folders and files in current directory&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;du -ahd1&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;sizes of all (including hidden) in current directory&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;em&gt;note&lt;/em&gt;&lt;/td&gt;
&lt;td&gt;pipe to &lt;code&gt;&amp;#124; sort -h[r]&lt;/code&gt; for result sorting&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;df - report file system disk space usage

SYNOPSIS
       df [OPTION]... [FILE]...
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;examples&lt;/th&gt;
&lt;th&gt;effects&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;df -h&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;disk usage in human readable form&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;example output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;Filesystem      Size  Used Avail Use% Mounted on
udev            990M  8.0K  990M   1% /dev
tmpfs           201M  944K  200M   1% /run
/dev/sda1        17G  6.3G  9.8G  40% /
none            4.0K     0  4.0K   0% /sys/fs/cgroup
none            5.0M     0  5.0M   0% /run/lock
none           1001M   23M  978M   3% /run/shm
none            100M   44K  100M   1% /run/user
Dropbox         238G  116G  123G  49% /media/sf_Dropbox
/dev/sr0         57M   57M     0 100% /media/user/VBOXADDITIONS_5.0.14_105127
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;system-related&#34;&gt;System Related&lt;/h2&gt;

&lt;p&gt;To check memory usage&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;commands&lt;/th&gt;
&lt;th&gt;effects&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;free -h&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;short summary&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;cat /proc/meminfo&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;show &lt;code&gt;meminfo&lt;/code&gt; file&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;top&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;show ram cpu usage per process, press e to scale units&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To put a process (e.g., mongod) to background,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ ^Z # ctrl + z to stop mongod
[1]+  Stopped mongod
$ bg
[1]+ mongod &amp;amp;
$ mongo
&amp;gt; ^C # can successfully connect
$ fg
mongod
^C
$ # back to bash
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;chmod - change file mode bits

SYNOPSIS
       chmod [OPTION]... MODE[,MODE]... FILE...
       chmod [OPTION]... OCTAL-MODE FILE...
       chmod [OPTION]... --reference=RFILE FILE...
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;examples&lt;/th&gt;
&lt;th&gt;effects&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;chmod +x file&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;permit the file as executable&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;code&gt;chmod 777 file&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;make the file globally readable, writable, executable by all users, groups, owner&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>MongoDB Tutorial 4 - Performance</title>
      <link>http://jessezhuang.github.io/article/mongodb-performance/</link>
      <pubDate>Fri, 24 Jun 2016 14:55:57 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/mongodb-performance/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;http://blog.technotesdesk.com/wp-content/uploads/2015/01/mongodb_logo.jpg&#34; alt=&#34;MongoDB Database&#34; title=&#34;MongoDB Logo&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;storage-engine&#34;&gt;Storage engine&lt;/h1&gt;

&lt;p&gt;Storage engine sits between mongodb server and the file storage. Use &lt;code&gt;db.serverStatus().storageEngine;&lt;/code&gt; to check.&lt;/p&gt;

&lt;h2 id=&#34;wiredtiger&#34;&gt;WiredTiger&lt;/h2&gt;

&lt;p&gt;for many applications, this is faster
- document level concurrency, lock free implementation. optimistic concurrency model which assumes two writes not gonna be on same document. if on same, one write unwound and try again.
- compression of data and indexes. WiredTiger manages memory.
- append only, no in place updates&lt;/p&gt;

&lt;h2 id=&#34;mmap-v1&#34;&gt;MMAP V1&lt;/h2&gt;

&lt;p&gt;Uses mmap system call undercovers. Allocating memory, or map files or devices into memory. Operation system manages memory/virtual memory.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;collection level locking, multiple reader, single writer lock.&lt;/li&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;http://blog.mongodb.org/post/248614779/fast-updates-with-mongodb-update-in-place&#34;&gt;in place update&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
 (database does not have to allocate and write a full new copy of the object).&lt;/li&gt;
&lt;li&gt;power of 2 sizes when allocating initial storage with a minimum of 32 bytes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;indexes&#34;&gt;Indexes&lt;/h1&gt;

&lt;p&gt;Built with btree or b+trees. With indexes writes are slower, reads are much faster. Without index, query on 10 million documents will be linear searching, too much disk io.&lt;/p&gt;

&lt;p&gt;(a,b,c) leftmost index order. a, (a,b), (a,b,c) would work, (a,c) partially work, others do not.&lt;/p&gt;

&lt;h2 id=&#34;indexes-size&#34;&gt;Indexes Size&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/mongodb-index-size.png&#34; alt=&#34;Indexes should fit into memory&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s essential to fit working set (key component: Indexes) into memory. To check indexes sizes in mongo shell:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.collection.stats() //detailed for each index
db.collection.totalIndexSize() //just the total
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a 10 million documents students collection, each index is about 300 Mb with &lt;a href=&#34;#mmap-v1&#34;&gt;MMAP V1 storage engine&lt;/a&gt;. Since 3.0, the &lt;a href=&#34;#wired-tiger&#34;&gt;wired tiger storage engine&lt;/a&gt; provides a few types of compression, one of which, i.e., prefix compression allows us to have smaller indexes. The same index is about 100 Mb instead of 300 Mb. The compression comes at the cost of CPU and whether the dataset can take advantage of something like prefix compression.&lt;/p&gt;

&lt;h2 id=&#34;number-of-index-entries-cardinality&#34;&gt;Number of Index Entries (Cardinality)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Regular: 1:1 proportional to collection size (index point needed even for null)&lt;/li&gt;
&lt;li&gt;Sparse: &amp;lt;= number of documents&lt;/li&gt;
&lt;li&gt;Multikey: index point for every array element. Could be (significantly) greater than number of documents.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If a document is updated and needs to be moved, the indexes need to be moved too. That cost only exists in the MMAPv1 storage engine. In the WiredTiger storage engine, index entries don&amp;rsquo;t contain pointers to actual disk locations. Instead, in WiredTiger, the index points to an internal document identifier (the 
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.org/manual/reference/method/cursor.showRecordId/?_ga=1.110860677.1452504667.1464414259#cursor.showRecordId&#34;&gt;Record Id&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
 that is immutable. Therefore, when a document is updated, its index does not need to be updated at all.&lt;/p&gt;

&lt;h2 id=&#34;geospatial-indexes&#34;&gt;Geospatial Indexes&lt;/h2&gt;

&lt;h3 id=&#34;2d-type&#34;&gt;2D Type&lt;/h3&gt;

&lt;p&gt;Allows to find things based on location. Documents have &lt;code&gt;&#39;location&#39;:[x,y]&lt;/code&gt; stored in them representing establishments around a person such as restaurants or coffee shops. &lt;code&gt;createIndex({&#39;location&#39;:&#39;2d&#39;, type:1})&lt;/code&gt; (2d is reserved type for two dimensional geo indexes). Use&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;find({location:{$near:[x0,y0]}}).limit(20)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to find closest establishments where &lt;code&gt;$near&lt;/code&gt; is a query operator and &lt;code&gt;[x0,y0]&lt;/code&gt; is ther person&amp;rsquo;s standing point.&lt;/p&gt;

&lt;h3 id=&#34;sperical-type&#34;&gt;Sperical Type&lt;/h3&gt;

&lt;p&gt;MongoDB supports a subset of 
&lt;a target=&#34;_blank&#34; href=&#34;http://geojson.org/geojson-spec.html&#34;&gt;GeoJSON location specification&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
. A GeoJSON document is used for the value of key &lt;code&gt;location&lt;/code&gt;. Google maps shows &lt;code&gt;@latitude,longitude&lt;/code&gt; as part of the url for a particular location. MongoDB takes an opposite order &lt;code&gt;@longitude,latitude&lt;/code&gt;. Although it&amp;rsquo;s a spherical model, it&amp;rsquo;s only looking at points at the surface of the sphere other than points in the air.&lt;/p&gt;

&lt;p&gt;First, create indexes,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.places.createIndex({&#39;location&#39;:&#39;2dsphere&#39;})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then, to find nearest point to hoover tower, in &lt;code&gt;geonear.js&lt;/code&gt;,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.places.find(
  location:{
    $near:{
      $geometry:{
        type:&amp;quot;Point&amp;quot;,
        coordinates:[-122,37]// hoover tower
      },
      $maxDistance:2000 // in meters
    }
  }).pretty()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to run the above query,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mongo &amp;lt; geonear.js
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;text-indexes&#34;&gt;Text Indexes&lt;/h2&gt;

&lt;p&gt;aka Full text search index. Typically, when searching strings, the entire string must match. Except that a regex search will search the index (rather than the full collection), and if you anchor it on the left by beginning with ^, you can often do better still. 
&lt;a target=&#34;_blank&#34; href=&#34;http://docs.mongodb.org/manual/reference/operator/query/regex/?_ga=1.222763675.1452504667.1464414259#index-use&#34;&gt;Here&amp;rsquo;s a link to the documentation&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
. Alternatively, put every word into an array and use set operators.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.sentences.createIndex({&#39;words&#39;:&#39;text&#39;})
db.sentences.find({$text:{$search:&#39;dog&#39;}})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A regular search &lt;code&gt;db.sentences.find({&#39;words&#39;:&#39;dog&#39;})&lt;/code&gt; will return nothing.&lt;/p&gt;

&lt;p&gt;We can rank the results by a score,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.sentences.find(
  {$text:{$search:&#39;dog tree obsidian&#39;}},
  {$score:{$meta:&#39;textScore&#39;}}
).sort({$score:{$meta:&#39;textScore&#39;}})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;index-design-i-class-fa-fa-arrow-up-aria-hidden-true-i&#34;&gt;Index Design &lt;a href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;The goal is efficient read/write operations.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Selectivity - minimize number of records scanned for a given query pattern.&lt;/li&gt;
&lt;li&gt;Other Ops - how sorts are handled?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example query for 1 million student records:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.students.find(
    {student_id:{$gt:500000}, class_id:54})
    .sort({student_id:1}).hint({class_id:1} // specify index shape
  ).explain(&amp;quot;executionstats&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note without &lt;code&gt;hint()&lt;/code&gt;, &lt;code&gt;&amp;quot;totalKeysExamined&amp;quot; : 850433&lt;/code&gt; &amp;gt;&amp;gt; &lt;code&gt;&amp;quot;nReturned&amp;quot; : 10118&lt;/code&gt;, so index was not very selective. Check &lt;code&gt;queryPlanner&lt;/code&gt;,  &lt;code&gt;winningPlan&lt;/code&gt;, and &lt;code&gt;rejectedPlans&lt;/code&gt; section, the student id query examines half of the collection. A query using &lt;code&gt;class_id&lt;/code&gt; as an index would need a in memory sort (&lt;code&gt;&amp;quot;stage&amp;quot; : &amp;quot;SORT&amp;quot;&lt;/code&gt;) instead of one within the database so was rejected. With &lt;code&gt;hint()&lt;/code&gt; &lt;code&gt;&amp;quot;totalKeysExamined&amp;quot; : 20071&lt;/code&gt;. &lt;code&gt;&amp;quot;executionTimeMillis&amp;quot;&lt;/code&gt; also dropped to 79 ms from 2600 ms.&lt;/p&gt;

&lt;p&gt;With &lt;code&gt;db.students.createIndex({class_id:1, student_id:1})&lt;/code&gt; we will be using the most selective part of the query which is an equality/point query other than the range query on the  &lt;code&gt;student_id&lt;/code&gt;. Generally speaking, order equality queries first when building a compound index.&lt;/p&gt;

&lt;p&gt;With the above compound index and query below,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.students.find(
    {student_id:{$gt:500000}, class_id:54}).sort({final_grade:1})
  ).explain(&amp;quot;executionstats&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;&amp;quot;totalKeysExamined&amp;quot;&lt;/code&gt; and &lt;code&gt;nReturned&lt;/code&gt; are 10118, &lt;code&gt;executionTimeMillis&lt;/code&gt; 138 ms with in memory sort on &lt;code&gt;final_grade&lt;/code&gt; done. It&amp;rsquo;s good to avoid in memory sort when you can, the trade off is to examine a few more keys. We can create another compound index, &lt;code&gt;db.students.createIndex({class_id:1, final_grade:1, student_id:1})&lt;/code&gt;, &lt;code&gt;final_grade&lt;/code&gt; has to be immediately after &lt;code&gt;class_id&lt;/code&gt; since we want to walk the index keys in order.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;db.students.find(
    {student_id:{$gt:500000}, class_id:54}).sort({final_grade:-1})
  ).explain(&amp;quot;executionstats&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now the result show &lt;code&gt;executionTimeMillis : 27&lt;/code&gt; and &lt;code&gt;&amp;quot;totalKeysExamined&amp;quot;: 10204&lt;/code&gt;. The &lt;code&gt;winningPlan&lt;/code&gt; now does not have a sort stage, only a &lt;code&gt;FETCH&lt;/code&gt; stage.&lt;/p&gt;

&lt;p&gt;MongoDB can walk the index backward in order to sort on the final_grade field. While true given that we are sorting on only this field, if we want to sort on multiple fields, the direction of each field on which we want to sort in a query must be the same as the direction of each field specified in the index. So if we want to sort using something like &lt;code&gt;db.collection.find( { a: 75 } ).sort( { a: 1, b: -1 } )&lt;/code&gt;, we must specify the index using the same directions, e.g., &lt;code&gt;db.collection.createIndex( { a: 1, b: -1 } )&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In general, the rules of thumb is
* Equality fields before range fields
* Sort fields before range fields
* Equality fields before sort fields&lt;/p&gt;

&lt;h2 id=&#34;logging-slow-queries&#34;&gt;Logging Slow queries&lt;/h2&gt;

&lt;p&gt;Slow queries longer than 100 ms are already automatically logged with the default logging facility. It takes about 4 s for &lt;code&gt;db.students.find({student_id:10000})&lt;/code&gt; without an index among 1 million student documents.&lt;/p&gt;

&lt;p&gt;There is a profiler built in &lt;code&gt;mongod&lt;/code&gt;, which is a more sophisticated facility and writes documents entries to system.profile any query taking more than specified time.
- level 0 off
- level 1 log slow queries
- level 2 log all queries, general debugging&lt;/p&gt;

&lt;p&gt;To start the profiler,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;mongod -dbpath /usr/local/var/mongodb --profile 1 --slowm 2
# logs queries above 2 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Use &lt;code&gt;db.system.profile.find().pretty()&lt;/code&gt; to check for slow queries. For the same above query,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;quot;query&amp;quot;:{
  &amp;quot;student_id&amp;quot; : 10000
}
&amp;quot;ntoreturn&amp;quot; : 0,
&amp;quot;nscanned&amp;quot; : 10000000,
...
&amp;quot;nReturned&amp;quot; : 1
&amp;quot;millis&amp;quot; : 4231
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a cap (fixed size) collection, recycle after it get used up. Some example usages below,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-javascript&#34;&gt;&amp;gt; db.system.profile.find({ns:/school.students/}).sort(ts:1).pretty()
// namespace school database, students collection, sort by timestamp.
&amp;gt; db.system.profile.find({millis:{$gt:1}}).sort(ts:1).pretty()
// looks for queries longer than 1 ms.
&amp;gt; db.getProfilingLevel()
1
&amp;gt; db.getProfilingStatus()
{&amp;quot;was&amp;quot; : 1, &amp;quot;slowms&amp;quot; : 2}
&amp;gt; db.setProfilingLevel(1, 4) // slow queries above 4 ms
{&amp;quot;was&amp;quot; : 1, &amp;quot;slowms&amp;quot; : 2, &amp;quot;ok&amp;quot; : 1}
&amp;gt; db.setProfilingLevel(0)
{&amp;quot;was&amp;quot; : 1, &amp;quot;slowms&amp;quot; : 4, &amp;quot;ok&amp;quot; : 1}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;mongotop-and-mongostat&#34;&gt;&lt;code&gt;mongotop&lt;/code&gt; and &lt;code&gt;mongostat&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;mongotop&lt;/code&gt; is named after &lt;a href=&#34;http://jessezhuang.github.io/
article/linux-cheatsheet/&#34;&gt;unix &lt;code&gt;top&lt;/code&gt;&lt;/a&gt;, which gives a high level view where mongo spends most of its time. Subsequently, one can follow up for more detailed examining and optimizing.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ mongotop 3 # default returns every second, this set to 3 seconds
ns                    total    read    write    2016-06-25T23:32:52-07:00
admin.system.roles      0ms     0ms      0ms                             
admin.system.version    0ms     0ms      0ms                             
blog.posts              0ms     0ms      0ms                             
blog.sessions           0ms     0ms      0ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;mongostat&lt;/code&gt; is a performance tuning command, similar to &lt;a href=&#34;http://jessezhuang.github.io/
article/linux-cheatsheet/which&#34;&gt;unix &lt;code&gt;iostat&lt;/code&gt;&lt;/a&gt; samples the database at 1 second increments and give information such as number of queries, inserts, updates, deletes, .etc. &lt;code&gt;getmore&lt;/code&gt; is getting more from a cursor for a query with a large result. &lt;code&gt;qr|qw ar|aw&lt;/code&gt; are queues and active reads and writes. &lt;code&gt;%dirty %used&lt;/code&gt; refers to percentage of WiredTiger cache. &lt;code&gt;res&lt;/code&gt; resident memory size smaller for WiredTiger. For MMAPv1 engine, &lt;code&gt;faults&lt;/code&gt; number of page faults and for WiredTiger, %used cache can indicate amount of IO being used. Check fields section for 
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/manual/reference/program/mongostat/&#34;&gt;mongostat doc&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;$ mongostat [--port 27017]
insert query update delete getmore command % dirty % used    res qr|qw ar|aw netIn netOut
    *0    *0     *0     *0       0     1|0     0.0    0.0  52.0M   0|0   0|0   79b    18k
    *0    *0     *0     *0       0     1|0     0.0    0.0  52.0M   0|0   0|0   79b    18k
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sharding-overview&#34;&gt;Sharding Overview&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/mongodb-sharding.png&#34; alt=&#34;mongodb sharding scheme&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Splitting a large collection amongst multiple servers. The details can be transparent to the client. &lt;code&gt;mongos&lt;/code&gt; routes to multiple &lt;code&gt;mongod&lt;/code&gt; shards. Each shard can contain multiple servers as a replica set.&lt;/p&gt;

&lt;p&gt;An insert must contain the shard key, e.g. &lt;code&gt;student_id&lt;/code&gt;. For update, remove, and find, if a shard key is not given, &lt;code&gt;mongos&lt;/code&gt; will have to broadcast the requests to all the shards.&lt;/p&gt;

&lt;h1 id=&#34;resources&#34;&gt;Resources&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://university.mongodb.com/courses/M101P/about&#34;&gt;MongoDB University Classes&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a target=&#34;_blank&#34; href=&#34;https://docs.mongodb.com/&#34;&gt;MongoDB Docs&lt;/a&gt; &lt;i class=&#34;fa fa-external-link&#34;&gt;&lt;/i&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&#34;#&#34;&gt;go to top &lt;i class=&#34;fa fa-arrow-up&#34; aria-hidden=&#34;true&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jessezhuang.github.io/
tags/mongodb/&#34;&gt;Link to the MongoDB tutorial series.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using Java&#39;s Reflection for Testing</title>
      <link>http://jessezhuang.github.io/article/java-reflection-test/</link>
      <pubDate>Sun, 19 Jun 2016 01:20:46 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/java-reflection-test/</guid>
      <description>

&lt;h2 id=&#34;writing-boilerplate-test-code-is-boring&#34;&gt;Writing Boilerplate Test Code is Boring&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://jessezhuang.github.io/img/java-reflection.png&#34; alt=&#34;Java Reflection&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Repeatedly writing boilerplate for loops for testing is not fun. We can use Java reflection API (&lt;code&gt;java.lang.reflect&lt;/code&gt; package) to maximize code reuse and help testing.&lt;/p&gt;

&lt;p&gt;Frameworks like JUnit uses reflection for testing. I will introduce a single method today on how reflection can be used for testing.&lt;/p&gt;

&lt;p&gt;The code examples below are available at my &lt;a href=&#34;https://github.com/JesseZhuang/SimpleJavaTools&#34;&gt;github repository&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;get-an-instance-of-class-being-tested&#34;&gt;Get an Instance of Class Being Tested&lt;/h2&gt;

&lt;p&gt;First we will declare a message to print out if all tests passed. Unfortunately you don&amp;rsquo;t usually get to see this message till the end of debugging.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final static String SUCCESS = &amp;quot;Congrats! All tests passed.&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Next we will make sure the input array and the expected result array have same number of elements with &lt;code&gt;validateLengths&lt;/code&gt; method which is trivial to implement.&lt;/p&gt;

&lt;p&gt;Then we will get a class type &lt;code&gt;Class&amp;lt;?&amp;gt;&lt;/code&gt; from the &lt;code&gt;className&lt;/code&gt; parameter, get the input class type with the first element of the input array &lt;code&gt;inputs[0]&lt;/code&gt;, and get the method being tested with &lt;code&gt;class.getMethod&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Lastly, we will instantiate an object for the class for the cases where the tested method is an instance method. If the method is a static method, this object will be ignored.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static &amp;lt;T, R&amp;gt; void assertEqual(String className,
  String methodName, T[] inputs, R[] expected) {
  // make sure they have same length
  validateLengths(inputs, expected);

  try {
    // use reflection to get type of class indicated by &amp;quot;className&amp;quot;
    Class&amp;lt;?&amp;gt; c = Class.forName(className);
    Class&amp;lt;T&amp;gt; inputType = (Class&amp;lt;T&amp;gt;) inputs[0].getClass();
    Method m = c.getMethod(methodName, inputType);

    // static methods will ignore this instance
    Object o = c.newInstance();
    // code continue in next block for actual testing
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;the-actual-testings&#34;&gt;The Actual Testings&lt;/h2&gt;

&lt;p&gt;Next we will use for loops to iterate over the array for all test cases. We write these loops here once and then we can call this method from the class being tested.&lt;/p&gt;

&lt;p&gt;For nested array, we have to test for deep equality. The testing will quit on the first failed test and print out the information about the input, output, and expected result.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;{ //continue from top
  {
    for (int i = 0; i &amp;lt; inputs.length; i++) {
      R e = expected[i];
      R output = (R) m.invoke(o, inputs[i]);

      // has to test deep equal for array type
      if (e.getClass().isArray()) {
        int n = Array.getLength(e);
        for (int j = 0; j &amp;lt; n; j++) {
          if (!Array.get(e, j).equals(Array.get(output, j))) {
            System.out.println(&amp;quot;test failed for &amp;quot;
              + Arrays.asList(inputs[i]) + &amp;quot; expected &amp;quot;
              + Arrays.asList(e) + &amp;quot;, output &amp;quot;
              + Arrays.asList(output));
            System.exit(-1);
          }
        }
      } else if (!e.equals(output)) {
        System.out.println(&amp;quot;test:\n &amp;quot; + inputs[i] + &amp;quot;failed, &amp;quot;
          + &amp;quot; expected &amp;quot; + expected + &amp;quot;, output &amp;quot; + output);
        System.exit(-1);
      }

    }

    // all tests passed
    System.out.println(SUCCESS);

  } catch (ClassNotFoundException | IllegalAccessException
    | IllegalArgumentException | InvocationTargetException
    | NoSuchMethodException | SecurityException
    | InstantiationException e) {
    //handle your exceptions here
    e.printStackTrace();
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;invoke-the-method-from-the-class-being-tested&#34;&gt;Invoke the Method from the Class Being Tested&lt;/h2&gt;

&lt;p&gt;To use the test method, call:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;TestClass.assertEqual(&amp;quot;my.pkg.className&amp;quot;,&amp;quot;methodName&amp;quot;,inputArray,
         expectedResultsArray);
&lt;/code&gt;&lt;/pre&gt;

&lt;div class=&#34;admonition note&#34;&gt;
&lt;p class=&#34;admonition-title&#34;&gt;Note&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t forget to include the package name in the first parameter as the class name. Please note that Class.getMethod() only searches for public methods.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Tutorial for using Hugo and Github Pages as a Blog Site</title>
      <link>http://jessezhuang.github.io/article/tutorial-hugoblog/</link>
      <pubDate>Sun, 19 Jun 2016 01:19:10 -0700</pubDate>
      
      <guid>http://jessezhuang.github.io/article/tutorial-hugoblog/</guid>
      <description>

&lt;h2 id=&#34;hugo-a-static-site-generator&#34;&gt;Hugo, a Static Site Generator&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.gohugo.io&#34;&gt;Hugo&lt;/a&gt; is one of the static site generators. Currently it is ranked 4th by &lt;a href=&#34;https://www.staticgen.com/&#34;&gt;StaticGen&lt;/a&gt;. Of the top competitors, Hugo is the only one written in a compiled language (Go), which builds the site much faster. So I decided to give it a spin.&lt;/p&gt;

&lt;p&gt;Most of them were written in JavaScript. &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; was the good old player in this field, which was used in Obama&amp;rsquo;s campaigns to raise $250M. Healthcare.gov switched to CMS-free style with Jekyll in 2013.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://hexo.io/&#34;&gt;Hexo&lt;/a&gt; uses node.js, which started in 2012. Hugo started in 2013. Both are getting quite popular within a short time. Hugo seems to have a nice growing community and fairly good documentations. It may be missing some features but let&amp;rsquo;s hope it will catch up.&lt;/p&gt;

&lt;h2 id=&#34;deployment-at-github-pages&#34;&gt;Deployment at Github Pages&lt;/h2&gt;

&lt;p&gt;I won&amp;rsquo;t be verbose about the benefits of static pages. Healthcare.gov and my blog here load blazing fast compared to dynamic sites where the server needs to pull data from different sources. The key reason for me is the flexibility of the content/design control. You are not limited by a small set of templates and widgets such as those found at &lt;a href=&#34;http://www.blogger.com&#34;&gt;Blogger&lt;/a&gt;. You don&amp;rsquo;t have the limitations at &lt;a href=&#34;http://www.wordpress.com&#34;&gt;Wordpress.com&lt;/a&gt; in case if you want to put ads on your blog.&lt;/p&gt;

&lt;p&gt;The ability to deploy the site with github pages is special since it connects with your github account and your repositories. The entire site can be version controlled as well as the generated site as a &lt;a href=&#34;https://git-scm.com/book/en/v2/Git-Tools-Submodules&#34;&gt;git submodule&lt;/a&gt;. You are basically making git commits in the meantime that you are updating your site.&lt;/p&gt;

&lt;h2 id=&#34;themes-for-hugo&#34;&gt;Themes for Hugo&lt;/h2&gt;

&lt;p&gt;There are a variety of templates available at Hugo&amp;rsquo;s &lt;a href=&#34;http://themes.gohugo.io/&#34;&gt;official site&lt;/a&gt;, covering different purposes from personal blog, documentation, project information, merchant, designer showcases, to many more. I really liked the &lt;a href=&#34;http://themes.gohugo.io/material-docs/&#34;&gt;material docs&lt;/a&gt; design, which was intended to be used as a project documentation/information site. I customized the template for a blog site.&lt;/p&gt;

&lt;h2 id=&#34;customize-the-hugo-material-docs-themes&#34;&gt;Customize the hugo-material-docs Themes&lt;/h2&gt;

&lt;p&gt;Main changes for the customization are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Changed the index page to list most recent posts/articles.&lt;/li&gt;
&lt;li&gt;Added sections to list blog categories and tags.&lt;/li&gt;
&lt;li&gt;Integrate &lt;a href=&#34;http://disqus.com&#34;&gt;Disqus&lt;/a&gt; comments at the bottom of each post.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The customized template is available at my &lt;a href=&#34;https://github.com/JesseZhuang/hugo-material-blog&#34;&gt;github repo here&lt;/a&gt;. The color pellets can be customized. I chose deep orange as the primary color hoping to warm up the cold coding talks.&lt;/p&gt;

&lt;p&gt;To use the template,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;git clone https://github.com/JesseZhuang/hugo-material-blog.git themes/hugo-material-blog
hugo -t hugo-material-blog
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or setup the theme in &lt;code&gt;config.yaml&lt;/code&gt; or &lt;code&gt;config.toml&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I did notice some weird bugs while I was customizing the template. Sometimes the template engine report errors if you have commented out lines in the template.&lt;/p&gt;

&lt;p&gt;I plan to keep this template updated while writing more articles for the site. You are welcome to comment here or at my &lt;a href=&#34;https://github.com/JesseZhuang/hugo-material-blog&#34;&gt;github repo&lt;/a&gt; for any issues or feature requests.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>http://jessezhuang.github.io/page/about-me/</link>
      <pubDate>Sat, 18 Jun 2016 00:11:02 +0100</pubDate>
      
      <guid>http://jessezhuang.github.io/page/about-me/</guid>
      <description>

&lt;h3 id=&#34;hello-people-my-name-is&#34;&gt;Hello People, My Name is&lt;/h3&gt;

&lt;h2 id=&#34;zexi-jesse-zhuang&#34;&gt;Zexi Jesse Zhuang,&lt;/h2&gt;

&lt;h2 id=&#34;a-developer-and-learner&#34;&gt;a Developer and Learner.&lt;/h2&gt;

&lt;p&gt;I currently live near Seattle, WA. I love web, mobile, and open source software development. I strive to find simple working solutions to complete tasks or goals and explain the algorithms and solutions concisely.&lt;/p&gt;

&lt;p&gt;Outside of coding, I love lifting, hiking, and badminton.&lt;/p&gt;

&lt;h2 id=&#34;why-coding-automaton&#34;&gt;Why Coding Automaton?&lt;/h2&gt;

&lt;p&gt;The first time I learned about Automaton was in &lt;a href=&#34;https://www.cs.princeton.edu/~rs/&#34;&gt;Robert Sedgewick&lt;/a&gt;&amp;rsquo;s Algorithms class. In &lt;a href=&#34;https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm&#34;&gt;Knuth Morris Pratt&lt;/a&gt;&amp;rsquo;s&amp;rsquo; substring search algorithm, a crucial step was to build the &lt;a href=&#34;https://en.wikipedia.org/wiki/Deterministic_finite_automaton&#34;&gt;deterministic finite state automaton (DFA)&lt;/a&gt;, which automatically tells about the next skip in substring search as the algorithm walks along the text to search for the pattern. As a programmer, one&amp;rsquo;s primary goal might be to generate automatic tools/products to simplify complicated jobs for other people and himself/herself. In this sense, I would like to get more proficient in coding as I write articles/tutorials and I hope my readers could benefit from the content as well.&lt;/p&gt;

&lt;h2 id=&#34;the-dry-principle&#34;&gt;The DRY Principle&lt;/h2&gt;

&lt;p&gt;In software engineering, &lt;a href=&#34;https://en.wikipedia.org/wiki/Don&#39;t_repeat_yourself&#34;&gt;don&amp;rsquo;t repeat yourself (DRY)&lt;/a&gt; is a principle aimed at reducing repetition of information of all kinds. I aim to write original contents here that are not easily found by googling. One other comprehension of the word automaton is to let the machine do the boring repeating tasks and free us humans for challenging and creative accomplishments. Whatever brings you here, I hope this blog can make it easier for you and myself to achieve our goals.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>